{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iH9xGN7tUDBW"
   },
   "source": [
    "# **Advances in Data Sciences and Architecture**\n",
    "## Name : **Rohan Kapadnis**\n",
    "## NUID : **1342161**\n",
    "## Assignment : **Mini Project 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lc_odKBjUetw"
   },
   "source": [
    "# **Main idea & Abstract of this Mini Project** \n",
    "\n",
    "### This project aims at demonstrating how to improve the quality of you machine learning models. This notebook will explain how to tackle categorical and numerical data types, how to use advanced techniques for model validation, how to avoid the problems of data leakage, as well as building pipeline to improve the code. And finally will demonstrate XGBoost which is one of the most widely used model in Kaggle.     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2ohmqZjWcPs"
   },
   "source": [
    "# **1. Introduction** \n",
    "\n",
    "## Here, we will be working with data from the \"Houses Prices Competition for Kaggle Learn Users\" for the demonstration. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-XCnaJptgGo"
   },
   "source": [
    "## The Data fields are as follows: \n",
    "SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\n",
    "\n",
    "MSSubClass: The building class\n",
    "\n",
    "MSZoning: The general zoning classification\n",
    "\n",
    "LotFrontage: Linear feet of street connected to property\n",
    "\n",
    "LotArea: Lot size in square feet\n",
    "\n",
    "Street: Type of road access\n",
    "\n",
    "Alley: Type of alley access\n",
    "\n",
    "LotShape: General shape of property\n",
    "\n",
    "LandContour: Flatness of the property\n",
    "\n",
    "Utilities: Type of utilities available\n",
    "\n",
    "LotConfig: Lot configuration\n",
    "\n",
    "LandSlope: Slope of property\n",
    "\n",
    "Neighborhood: Physical locations within Ames city limits\n",
    "\n",
    "Condition1: Proximity to main road or railroad\n",
    "\n",
    "Condition2: Proximity to main road or railroad (if a second is present)\n",
    "\n",
    "BldgType: Type of dwelling\n",
    "\n",
    "HouseStyle: Style of dwelling\n",
    "\n",
    "OverallQual: Overall material and finish quality\n",
    "\n",
    "OverallCond: Overall condition rating\n",
    "\n",
    "YearBuilt: Original construction date\n",
    "\n",
    "YearRemodAdd: Remodel date\n",
    "\n",
    "RoofStyle: Type of roof\n",
    "\n",
    "RoofMatl: Roof material\n",
    "\n",
    "Exterior1st: Exterior covering on house\n",
    "\n",
    "Exterior2nd: Exterior covering on house (if more than one material)\n",
    "\n",
    "MasVnrType: Masonry veneer type\n",
    "\n",
    "MasVnrArea: Masonry veneer area in square feet\n",
    "\n",
    "ExterQual: Exterior material quality\n",
    "\n",
    "ExterCond: Present condition of the material on the exterior\n",
    "\n",
    "Foundation: Type of foundation\n",
    "\n",
    "BsmtQual: Height of the basement\n",
    "\n",
    "BsmtCond: General condition of the basement\n",
    "\n",
    "BsmtExposure: Walkout or garden level basement walls\n",
    "\n",
    "BsmtFinType1: Quality of basement finished area\n",
    "\n",
    "BsmtFinSF1: Type 1 finished square feet\n",
    "\n",
    "BsmtFinType2: Quality of second finished area (if present)\n",
    "\n",
    "BsmtFinSF2: Type 2 finished square feet\n",
    "\n",
    "BsmtUnfSF: Unfinished square feet of basement area\n",
    "\n",
    "TotalBsmtSF: Total square feet of basement area\n",
    "\n",
    "Heating: Type of heating\n",
    "\n",
    "HeatingQC: Heating quality and condition\n",
    "\n",
    "CentralAir: Central air conditioning\n",
    "\n",
    "Electrical: Electrical system\n",
    "\n",
    "1stFlrSF: First Floor square feet\n",
    "\n",
    "2ndFlrSF: Second floor square feet\n",
    "\n",
    "LowQualFinSF: Low quality finished square feet (all floors)\n",
    "\n",
    "GrLivArea: Above grade (ground) living area square feet\n",
    "\n",
    "BsmtFullBath: Basement full bathrooms\n",
    "\n",
    "BsmtHalfBath: Basement half bathrooms\n",
    "\n",
    "FullBath: Full bathrooms above grade\n",
    "\n",
    "HalfBath: Half baths above grade\n",
    "\n",
    "Bedroom: Number of bedrooms above basement level\n",
    "\n",
    "Kitchen: Number of kitchens\n",
    "\n",
    "KitchenQual: Kitchen quality\n",
    "\n",
    "TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
    "\n",
    "Functional: Home functionality rating\n",
    "\n",
    "Fireplaces: Number of fireplaces\n",
    "\n",
    "FireplaceQu: Fireplace quality\n",
    "\n",
    "GarageType: Garage location\n",
    "\n",
    "GarageYrBlt: Year garage was built\n",
    "\n",
    "GarageFinish: Interior finish of the garage\n",
    "\n",
    "GarageCars: Size of garage in car capacity\n",
    "\n",
    "GarageArea: Size of garage in square feet\n",
    "\n",
    "GarageQual: Garage quality\n",
    "\n",
    "GarageCond: Garage condition\n",
    "\n",
    "PavedDrive: Paved driveway\n",
    "\n",
    "WoodDeckSF: Wood deck area in square feet\n",
    "\n",
    "\n",
    "OpenPorchSF: Open porch area in square feet\n",
    "\n",
    "EnclosedPorch: Enclosed porch area in square feet\n",
    "\n",
    "3SsnPorch: Three season porch area in square feet\n",
    "\n",
    "ScreenPorch: Screen porch area in square feet\n",
    "\n",
    "PoolArea: Pool area in square feet\n",
    "\n",
    "PoolQC: Pool quality\n",
    "\n",
    "Fence: Fence quality\n",
    "\n",
    "MiscFeature: Miscellaneous feature not covered in other categories\n",
    "\n",
    "MiscVal: $Value of miscellaneous feature\n",
    "\n",
    "MoSold: Month Sold\n",
    "\n",
    "YrSold: Year Sold\n",
    "\n",
    "SaleType: Type of sale\n",
    "\n",
    "SaleCondition: Condition of sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UBawsefXz8X5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CMqeSCPT3aW"
   },
   "outputs": [],
   "source": [
    "url_test = 'https://raw.githubusercontent.com/rohan-kapadnis/Advances-in-Data-Sciences-and-Architecture/master/Mini-Project%201/dataset/test.csv'\n",
    "url_train = 'https://raw.githubusercontent.com/rohan-kapadnis/Advances-in-Data-Sciences-and-Architecture/master/Mini-Project%201/dataset/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RuI-YJCjzhmM"
   },
   "outputs": [],
   "source": [
    "#Read the data\n",
    "X_full = pd.read_csv(url_train)\n",
    "X_test_full = pd.read_csv(url_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "_IfbgtekDMWf",
    "outputId": "3ef872df-abaa-48b4-a465-9ad8d72f49aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>...</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>GasA</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>216</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>GasA</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>655</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>GasA</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n",
       "0   1          60       RL  ...        WD         Normal    208500\n",
       "1   2          20       RL  ...        WD         Normal    181500\n",
       "2   3          60       RL  ...        WD         Normal    223500\n",
       "3   4          70       RL  ...        WD        Abnorml    140000\n",
       "4   5          60       RL  ...        WD         Normal    250000\n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Si1bZwkl2xPN"
   },
   "source": [
    "# **2. Handling missing values**\n",
    "\n",
    "### **Approaches** : \n",
    "### 1) Drop Columns with missing values\n",
    "      This is the simplest option. To drop columns with missing values. \n",
    "      But due to this method, model loses access to a lot of potentially useful information. \n",
    "\n",
    "### 2) Imputation : \n",
    "      Imputation fills in the missing vlues with some number. \n",
    "      For eg, we can fill in the mean value along each column. \n",
    "      The imputed value won't be exactly right in most cases, \n",
    "      but it usually leads to more accurate models than you would get from dropping the column entirely.\n",
    "\n",
    "\n",
    "### 3) Extension to imputation : \n",
    "       In this approach, we impute the missing values, as before. \n",
    "       And, additionally, for each column with missing entries in the original dataset,\n",
    "       we add a new column that shows the location of the imputed entries.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzXh_4_J09sv"
   },
   "source": [
    "### **Hands on** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOlTxhvaz6we"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# To keep things simple, we'll use only numerical predictors\n",
    "X = X_full.select_dtypes(exclude=['object'])\n",
    "X_test = X_test_full.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "H-_1uW7UC781",
    "outputId": "ec4c0e88-ad0c-47c0-eab7-45b4134151d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>619</td>\n",
       "      <td>20</td>\n",
       "      <td>90.0</td>\n",
       "      <td>11694</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>452.0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1774</td>\n",
       "      <td>1822</td>\n",
       "      <td>1828</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1828</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>3</td>\n",
       "      <td>774</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>871</td>\n",
       "      <td>20</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6600</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1962</td>\n",
       "      <td>1962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>1</td>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>30</td>\n",
       "      <td>80.0</td>\n",
       "      <td>13360</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1921</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>713</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>876</td>\n",
       "      <td>964</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>964</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>2</td>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>818</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13265</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1218</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "      <td>1568</td>\n",
       "      <td>1689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1689</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>3</td>\n",
       "      <td>857</td>\n",
       "      <td>150</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>303</td>\n",
       "      <td>20</td>\n",
       "      <td>118.0</td>\n",
       "      <td>13704</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1541</td>\n",
       "      <td>1541</td>\n",
       "      <td>1541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3</td>\n",
       "      <td>843</td>\n",
       "      <td>468</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  MSSubClass  LotFrontage  LotArea  ...  PoolArea  MiscVal  MoSold  YrSold\n",
       "618  619          20         90.0    11694  ...         0        0       7    2007\n",
       "870  871          20         60.0     6600  ...         0        0       8    2009\n",
       "92    93          30         80.0    13360  ...         0        0       8    2009\n",
       "817  818          20          NaN    13265  ...         0        0       7    2008\n",
       "302  303          20        118.0    13704  ...         0        0       1    2006\n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zE96Q6D5368S"
   },
   "source": [
    "As you can see, there are a few MISSING VALUES!!!!\n",
    "\n",
    "We will try to investigate them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OC4NDkUK33lY",
    "outputId": "95413232-56d4-4252-f4ab-99719716229c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 37)\n",
      "LotFrontage    212\n",
      "MasVnrArea       6\n",
      "GarageYrBlt     58\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Shape of training data \n",
    "print(X_train.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3tq3Aa37c4a"
   },
   "source": [
    "As there are quite a few missing values, we will try to use imputation instead of dropping columns as that won't lose any valuable information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-n1ocmP7vqO"
   },
   "source": [
    "To compare these approaches, we will define a function called score_dataset() that will return Mean Absolute Error from a Random Forest Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFkrwAVb4zfD"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KL6iS0ih9odB"
   },
   "source": [
    "## A. **Dropping column with missing values**  method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "guYaeWiB8g9V"
   },
   "outputs": [],
   "source": [
    "#get names of columns with missing values\n",
    "cols_with_missing = [col for col in X_train.columns\n",
    "                     if X_train[col].isnull().any()]\n",
    "\n",
    "# Drop columns in training and validation data\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lhsnL4qe89IH",
    "outputId": "eb39124d-2273-4375-b531-2814f63d2170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Drop columns with missing values):\n",
      "17952.591404109586\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE (Drop columns with missing values):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JT7yfmTU98zL"
   },
   "source": [
    "## B. **Imputation** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NJkgZm6z9FMB"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# Imputation removed column names; putting them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zbus9C2kE2xi",
    "outputId": "8671a405-9f17-4aa0-d7d4-4e519d637d8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Imputation):\n",
      "18250.608013698627\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE (Imputation):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DG19P0I88Pzz",
    "outputId": "f3b01077-d7cf-4275-f563-089284c29a9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1168 entries, 618 to 684\n",
      "Data columns (total 37 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1168 non-null   int64  \n",
      " 1   MSSubClass     1168 non-null   int64  \n",
      " 2   LotFrontage    956 non-null    float64\n",
      " 3   LotArea        1168 non-null   int64  \n",
      " 4   OverallQual    1168 non-null   int64  \n",
      " 5   OverallCond    1168 non-null   int64  \n",
      " 6   YearBuilt      1168 non-null   int64  \n",
      " 7   YearRemodAdd   1168 non-null   int64  \n",
      " 8   MasVnrArea     1162 non-null   float64\n",
      " 9   BsmtFinSF1     1168 non-null   int64  \n",
      " 10  BsmtFinSF2     1168 non-null   int64  \n",
      " 11  BsmtUnfSF      1168 non-null   int64  \n",
      " 12  TotalBsmtSF    1168 non-null   int64  \n",
      " 13  1stFlrSF       1168 non-null   int64  \n",
      " 14  2ndFlrSF       1168 non-null   int64  \n",
      " 15  LowQualFinSF   1168 non-null   int64  \n",
      " 16  GrLivArea      1168 non-null   int64  \n",
      " 17  BsmtFullBath   1168 non-null   int64  \n",
      " 18  BsmtHalfBath   1168 non-null   int64  \n",
      " 19  FullBath       1168 non-null   int64  \n",
      " 20  HalfBath       1168 non-null   int64  \n",
      " 21  BedroomAbvGr   1168 non-null   int64  \n",
      " 22  KitchenAbvGr   1168 non-null   int64  \n",
      " 23  TotRmsAbvGrd   1168 non-null   int64  \n",
      " 24  Fireplaces     1168 non-null   int64  \n",
      " 25  GarageYrBlt    1110 non-null   float64\n",
      " 26  GarageCars     1168 non-null   int64  \n",
      " 27  GarageArea     1168 non-null   int64  \n",
      " 28  WoodDeckSF     1168 non-null   int64  \n",
      " 29  OpenPorchSF    1168 non-null   int64  \n",
      " 30  EnclosedPorch  1168 non-null   int64  \n",
      " 31  3SsnPorch      1168 non-null   int64  \n",
      " 32  ScreenPorch    1168 non-null   int64  \n",
      " 33  PoolArea       1168 non-null   int64  \n",
      " 34  MiscVal        1168 non-null   int64  \n",
      " 35  MoSold         1168 non-null   int64  \n",
      " 36  YrSold         1168 non-null   int64  \n",
      "dtypes: float64(3), int64(34)\n",
      "memory usage: 346.8 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBwoPHZ3GiQ-"
   },
   "source": [
    "Given that thre are so few missing values in the dataset, we'd expect imputation to perform better than dropping columns entirely. However, we see that dropping columns performs slightly better! While this can probably partially be attributed to noise in the dataset, another potential explanation is that the imputation method is not a great match to this dataset. That is, maybe instead of filling in the mean value, it makes more sense to set every missing value to a value of 0, to fill in the most frequently encountered value, or to use some other method. For instance, consider the GarageYrBlt column (which indicates the year that the garage was built). It's likely that in some cases, a missing value could indicate a house that does not have a garage. Does it make more sense to fill in the median value along each column in this case? Or could we get better results by filling in the minimum value along each column? It's not quite clear what's best in this case, but perhaps we can rule out some options immediately - for instance, setting missing values in this column to 0 is likely to yield horrible results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIXSgMehJbZr"
   },
   "source": [
    "# **3. Categorical Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQHzbWL4rbNw"
   },
   "source": [
    "### Categorical variables are variables that take only limited number of values. \n",
    "#### eg. For a survey of gender the outcomes are Male and Female \n",
    "\n",
    "#### You will get an error if you try to plug these variables into most machine learning models in Python without preprocessing them first. There are various approaches that can be used to prepare categorical data\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6lAyC9QtHrx"
   },
   "source": [
    "### **Approaches** : \n",
    "### 1) Drop categorical variables\n",
    "      The easiest approach to dealing with categorical variables is to simply remove them from the dataset. \n",
    "      This approach will only work well if the columns did not contain useful information. \n",
    "\n",
    "\n",
    "### 2) Label Encoding\n",
    "      Label encoding assigns each unique value to a different integer.\n",
    "      Not all categorical variables have a clear ordering in the values, \n",
    "      but we refer to those that do as ordinal variables.\n",
    "      eg,  \"Never\" (0) < \"Rarely\" (1) < \"Most days\" (2) < \"Every day\" (3)\n",
    "\n",
    "### 3) One-Hot Encoding\n",
    "      One-hot encoding creates new columns indicating the presence \n",
    "      (or absence) of each possible value in the original data.\n",
    "   \n",
    "![Screen Shot 2020-10-28 at 8 29 35 PM](https://user-images.githubusercontent.com/56054175/97792780-4eceaf80-1bb9-11eb-810e-c746f1a2c5a5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn6hqFF_z1pq"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "One-hot encoding generally does not perform well if the \n",
    "categorical variable takes on a large number of values \n",
    "(i.e., you generally won't use it for variables taking more than 15 different values).\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SD1Dmwps1C2Z"
   },
   "source": [
    "### **Hands on** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X_Ac0J-3flr"
   },
   "source": [
    "## A. **Dropping column with categorical data**  method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShT8lPoJz-i5"
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(url_train)\n",
    "X_test = pd.read_csv(url_test)\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# To keep things simple, we'll drop columns with missing values\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
    "X.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVHx0yUmEj0p"
   },
   "outputs": [],
   "source": [
    "# Drop columns in training and validation data\n",
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fL3oqZvF3op1",
    "outputId": "460785a4-3dea-4061-eeeb-843947d6e8b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "17952.591404109586\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmMkoHEO4qou"
   },
   "source": [
    "## B. **Label Encoding**  method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_AN5Yo935Bf",
    "outputId": "ffa7b008-7a63-4d49-efbb-4ba90e3752c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be label encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'LotConfig', 'BldgType', 'HouseStyle', 'ExterQual', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['RoofMatl', 'SaleType', 'Functional', 'HeatingQC', 'LandSlope', 'Condition1', 'Heating', 'Utilities', 'Condition2', 'Foundation', 'Exterior1st', 'ExterCond', 'Exterior2nd', 'RoofStyle', 'Neighborhood']\n"
     ]
    }
   ],
   "source": [
    "# All categorical columns\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "\n",
    "# Columns that can be safely label encoded\n",
    "good_label_cols = [col for col in object_cols if set(X_train[col]) == set(X_valid[col])]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be label encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4WpMo1Yn56tg",
    "outputId": "3a2e7ab1-e073-44b4-dd19-9d8826af6f16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Label Encoding):\n",
      "17675.942500000005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Apply label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "for col in set(good_label_cols):\n",
    "    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    label_X_valid[col] = label_encoder.transform(X_valid[col])\n",
    "\n",
    "print(\"MAE from Approach 2 (Label Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ilho8t1UbUh2"
   },
   "source": [
    "**Here, clearly Encoding performed better than Dropping Columns method**\n",
    "\n",
    "\n",
    "We will try the One-Hot Encoding method next "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_1ilXqYcx7o"
   },
   "source": [
    "## C. **One-Hot Encoding**  method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGN-gS4uc6-X"
   },
   "source": [
    "####Finding the cardinality(number of unique entries in each column with categorical data) of the Categorical columns first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKoWNueF9kv3",
    "outputId": "b380054b-293e-4028-e522-2201670d9106"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Street', 2),\n",
       " ('Utilities', 2),\n",
       " ('CentralAir', 2),\n",
       " ('LandSlope', 3),\n",
       " ('PavedDrive', 3),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('ExterQual', 4),\n",
       " ('KitchenQual', 4),\n",
       " ('MSZoning', 5),\n",
       " ('LotConfig', 5),\n",
       " ('BldgType', 5),\n",
       " ('ExterCond', 5),\n",
       " ('HeatingQC', 5),\n",
       " ('Condition2', 6),\n",
       " ('RoofStyle', 6),\n",
       " ('Foundation', 6),\n",
       " ('Heating', 6),\n",
       " ('Functional', 6),\n",
       " ('SaleCondition', 6),\n",
       " ('RoofMatl', 7),\n",
       " ('HouseStyle', 8),\n",
       " ('Condition1', 9),\n",
       " ('SaleType', 9),\n",
       " ('Exterior1st', 15),\n",
       " ('Exterior2nd', 16),\n",
       " ('Neighborhood', 25)]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DKJcvEKdRzh"
   },
   "source": [
    "**Columns having high cardinality will pose a problem as they would expand the size of the dataset significantly. High cardinality columns can either be dropped from the dataset, or we can use label encoding.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqVuCRjiezjc"
   },
   "source": [
    "For our project, we will create one hot encoding for columns with cardinality less than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-wmXQMPEdDaI",
    "outputId": "f5d27e16-3054-44e8-ff17-0d9d2a16141a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be one-hot encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Exterior1st', 'Neighborhood', 'Exterior2nd']\n"
     ]
    }
   ],
   "source": [
    "# Columns that will be one-hot encoded\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjKtoTcPfIgD"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCUL8yNjfSKD",
    "outputId": "a0d4afc0-7d03-467b-dd0f-dcac8c4c2b0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (One-Hot Encoding):\n",
      "17514.224246575344\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Nj_j7NtfmMg"
   },
   "source": [
    "Hence, One hot encoding performs the best out of the 3 methods with least MAE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4fCUwjsA0xX"
   },
   "source": [
    "# **3. Pipelines**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOWMaFj84M_s"
   },
   "source": [
    "###**Pipelines** are a simple way to keep your **data preprocessing and modeling code organized**. Specifically, a pipeline bundles preprocessing and modeling steps so you can use the whole bundle as if it were a single step.\n",
    "\n",
    "###Many data scientists hack together models without pipelines, but pipelines have some important benefits. Those include:\n",
    "\n",
    "####**Cleaner Code**: Accounting for data at each step of preprocessing can get messy. With a pipeline, you won't need to manually keep track of your training and validation data at each step.\n",
    "\n",
    "####**Fewer Bugs**: There are fewer opportunities to misapply a step or forget a preprocessing step.\n",
    "\n",
    "####**Easier to Productionize**: It can be surprisingly hard to transition a model from a prototype to something deployable at scale. We won't go into the many related concerns here, but pipelines can help.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmGHWwzV6d7L"
   },
   "source": [
    "### **Hands on** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "euL2PhjzffZG"
   },
   "outputs": [],
   "source": [
    "X_full = pd.read_csv(url_train)\n",
    "X_test_full = pd.read_csv(url_test)\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n",
    "                                                                train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in X_train_full.columns if\n",
    "                    X_train_full[cname].nunique() < 10 and \n",
    "                    X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hgmdi2_Y6oG2",
    "outputId": "e525f421-f13f-4209-bd1f-7977ac2a903f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>Ex</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Ex</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>619</td>\n",
       "      <td>20</td>\n",
       "      <td>90.0</td>\n",
       "      <td>11694</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>452.0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1774</td>\n",
       "      <td>1822</td>\n",
       "      <td>1828</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1828</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>3</td>\n",
       "      <td>774</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>PosN</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>None</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>N</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>871</td>\n",
       "      <td>20</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6600</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1962</td>\n",
       "      <td>1962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>1</td>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>None</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>93</td>\n",
       "      <td>30</td>\n",
       "      <td>80.0</td>\n",
       "      <td>13360</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1921</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>713</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>876</td>\n",
       "      <td>964</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>964</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>2</td>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>818</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13265</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1218</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "      <td>1568</td>\n",
       "      <td>1689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1689</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>3</td>\n",
       "      <td>857</td>\n",
       "      <td>150</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Unf</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>303</td>\n",
       "      <td>20</td>\n",
       "      <td>118.0</td>\n",
       "      <td>13704</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1541</td>\n",
       "      <td>1541</td>\n",
       "      <td>1541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3</td>\n",
       "      <td>843</td>\n",
       "      <td>468</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSZoning Street Alley LotShape  ... PoolArea MiscVal MoSold YrSold\n",
       "618       RL   Pave   NaN      Reg  ...        0       0      7   2007\n",
       "870       RL   Pave   NaN      Reg  ...        0       0      8   2009\n",
       "92        RL   Pave  Grvl      IR1  ...        0       0      8   2009\n",
       "817       RL   Pave   NaN      IR1  ...        0       0      7   2008\n",
       "302       RL   Pave   NaN      IR1  ...        0       0      1   2006\n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54rAp8QR6-Lw"
   },
   "source": [
    "###Step 1: **Define Preprocessing Steps**\n",
    "We will use the ColumnTransformer class to bundle together different preprocessing steps. \n",
    "\n",
    "The code below:\n",
    " - imputes missing values in numerical data\n",
    " - imputes missing values and applies a one-hot encoding to categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bKpPBpuf6wts"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8s2RJTM-DOf"
   },
   "source": [
    "###Step 2: **Define the model**\n",
    "We will now define a random forest model with the familiar RandomForestRegressor class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rPI1swF9E-C"
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fvs6LSx8ANot"
   },
   "source": [
    "###Step 3: **Create and Evaluate the Pipeline**\n",
    "\n",
    "We use the Pipeline class to define a pipeline that bundles the preprocessing and modeling steps\n",
    " - With the pipeline, we preprocess the training data and fit the model in a single line of code\n",
    "\n",
    " - With the pipeline, we supply the unprocessed features in X_valid to the predict() command, and the pipeline automatically preprocesses the features before generating predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhbLA0qZ_3dh",
    "outputId": "f284bc75-fc1b-4d59-e843-0fd647459bcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 17740.290308219177\n"
     ]
    }
   ],
   "source": [
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)\n",
    "                     ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = clf.predict(X_valid)\n",
    "\n",
    "print('MAE:', mean_absolute_error(y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pz3WdS3zEcp1"
   },
   "source": [
    "Hence, pipelines are valuable for cleaning up machine learning code and avoiding errors, and are especially useful for workflows with sophisticated data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8iN2HUWG-hF"
   },
   "source": [
    "# **4. Cross-Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgHAiOHFQi-c"
   },
   "source": [
    "### In cross-validation, we run our modeling process on different subsets of the data to get multiple measures of model quality.\n",
    "\n",
    "For example, we could begin by dividing the data into 5 pieces, each 20% of the full dataset. In this case, we say that we have broken the data into 5 \"folds\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9GsZjzeQlWt"
   },
   "source": [
    "![Screen Shot 2020-10-29 at 5.26.24 PM.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAfUAAADcCAYAAABpnDhbAAABQWlDQ1BJQ0MgUHJvZmlsZQAAKJFjYGDiSSwoyGFhYGDIzSspCnJ3UoiIjFJgf8LAxSDLwM+gwmCYmFxc4BgQ4ANUwgCjUcG3awyMIPqyLsisXnPXJeXSmdbFpjejNxxatgJTPQrgSkktTgbSf4A4IbmgqISBgTEGyFYuLykAsRuAbJEioKOA7CkgdjqEDTJXJAnC3gNWExLkDGRfALIFkjMSU4DsB0C2ThKSeDoSG2ovCLA5OxmZGxFwKKmgJLWiBEQ75xdUFmWmZ5QoOAJDJ1XBMy9ZT0fByMDIgIEBFNYQ1Z+DwGHIKLYPIZa/hIHB4hsDA/NEhFgSMAy2tzEwSNxCiKnMY2Dgb2Fg2HaoILEoEe4Axm8sxWnGEG8x8tgzMLDe/f//swYDA/tEBoa/E////734//+/i4Hm32ZgOFAJALpDXngXEnmVAAAAVmVYSWZNTQAqAAAACAABh2kABAAAAAEAAAAaAAAAAAADkoYABwAAABIAAABEoAIABAAAAAEAAAH1oAMABAAAAAEAAADcAAAAAEFTQ0lJAAAAU2NyZWVuc2hvdILrvpsAAAHWaVRYdFhNTDpjb20uYWRvYmUueG1wAAAAAAA8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIiB4OnhtcHRrPSJYTVAgQ29yZSA1LjQuMCI+CiAgIDxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+CiAgICAgIDxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSIiCiAgICAgICAgICAgIHhtbG5zOmV4aWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20vZXhpZi8xLjAvIj4KICAgICAgICAgPGV4aWY6UGl4ZWxYRGltZW5zaW9uPjUwMTwvZXhpZjpQaXhlbFhEaW1lbnNpb24+CiAgICAgICAgIDxleGlmOlVzZXJDb21tZW50PlNjcmVlbnNob3Q8L2V4aWY6VXNlckNvbW1lbnQ+CiAgICAgICAgIDxleGlmOlBpeGVsWURpbWVuc2lvbj4yMjA8L2V4aWY6UGl4ZWxZRGltZW5zaW9uPgogICAgICA8L3JkZjpEZXNjcmlwdGlvbj4KICAgPC9yZGY6UkRGPgo8L3g6eG1wbWV0YT4KyLLGJAAAQABJREFUeAHsnQVgFMcax/9x9xAgSHAJEtwdSpFC8bZQL9RendL2tdSot1SovbrRFkqhQHF3dwIhEAiBICFC3OXef/ZuLxfBSTiSbyB3u7OzI7+ZnW++b2b2bAx0ECcEhIAQEAJCQAjc9ARsb/oSSAGEgBAQAkJACAgBjYAIdWkIQkAICAEhIAQqCAER6hWkIqUYQkAICAEhIAREqEsbEAJCQAgIASFQQQiIUK8gFSnFEAJCQAgIASEgQl3agBAQAkJACAiBCkJAhHoFqUgphhAQAkJACAgBEerSBoSAEBACQkAIVBACItQrSEVKMYSAEBACQkAIiFCXNiAEhIAQEAJCoIIQEKFeQSpSiiEEhIAQEAJCQIS6tAEhIASEgBAQAhWEgAj1ClKRUgwhIASEgBAQAiLUpQ0IASEgBISAEKggBESoV5CKlGIIASEgBISAELAXBEJACFRuAptPncewH1YRgg1y8guQnJWDKm7OPDfAxtEB514eViqg8wz38eYIvNOnWanXdc+cvAJUfWsOEt8crXtd8Ht1VCyenrcboc8MuGAYdeGbbcfQItAHXWv5XjTc1VzceToRO2OS8Gjbuldzu9wjBG4oAdHUbyj+8kt8+v6T+JwdoTghUJxAl5q+iH1jNP9GYdb43qjq4aIdK78LCXQVR0JmDt5deaB4dNd0btDuNn5eLKIft0ZgU3T8xYJc9bUdHOT8tFOelasGWElu3Bp9Hqk5uVZXWhHqVlclZZOhdcfjsOTwmbKJXGKtMARsqK0rjd3SzY84B79358Fxyhz8sO+kdmkrtdl7/toK5Oai90/rcDYtCzkFBXh66T44vTkbvu/OxY97TxRGcwE5nV9gwH1zd8Dm1VkY9OdmGArULcb0c3lt8tpDcGC6blP+wS+m+Pr+sh6R8cn4ZvNhvLB8v5bG/rgUhHyzAjaT/0Kvn9eZO1tlTRj51xbYvDwT7b5dhf3xqeY8HU/OQJPPl8GN+f1k6zEYDAZ8yu9pG8Oxl+Xr/eNa+pmDy4EQKEJgKK1bBxPSi/hZw4mY362hFsolDwbsPBaDTt+vLppa0f7bdM1irFfqdVMw/ZqNOlC9n+5heWwKq67Z0N+gvpVfsTD6rVpwixOLQz2mIt9F0jbGqd9ix4DaZfWt/TOeq2yoPKhS6mHVt1GgGcPwVLum51ILxxtsTPm2vE8VydYUsNDfeKSfq8j0Yz0dxcDGlEH9mkpXOeVvUNe1f0Y/zV9d009NB3p5jNeNdVdYbpVKAe+x1WKaPqKdfvdFvlVhjO7NDeH4nn/TR3eCvb0tJszcgkM0Tf+3RxM83KkhttFc/mKvJvB2csDDFM7ZNN+vebAPTqVm4IHf1uOhVkHGiMyZ1mOGNghoNm0pWgZ4Yf2EPgiNScHIn9eitp+nFuipJXux91QC1j3QG2nZuRg7fQPa06owqWcTPBObjO4NA3FHy9pI4bUeny/Fp6M6oomvB77cFoFRf2zGsgd6YuzMraju7Yqtj9+KVVHnOM2wGpEv3Y6YjGx05j2fjWiPKq5OmDB7K3Lz8zC0cSCOJ6RgxZGzeLF308LMFjs6lZKJr0yWL61oFuVTh+pPbzvqVnOdm8JpX+ZAxqumSyq42dnYmgNpcZYaxsLT4tDc9lVkZn8emPNi9jfm1OhvrHu9XRa5V4W3aJfqmnIqbtXeLMurXTBdUwG0Nmr2tMyB8X51SWu5NvxUIzt+q3iNH+Yv5aN7mY61UEU8TT4qCrPT/Uw3meIomg91zTKc8Rm6QBgGzOW0kjU6EerWWCtllCcvdl5tq3iZW67x8S1MrFArKbxSeFQYTh0VhtXOtItKBBmd8fFWmk9xV8KHD7BBe5wLHxDjubrT5KdFZ6sJJz2+klGb0tQCWKRCiauEo7HQRn+Lq3p0Wo9kebVkGFU2o5jVkygSxixZjanpEZrDmA/U3XoYHlIb1ZypL9Pus+CormpltURrvEP7NEerDkxhLP3MxxoDixsv8/C3TYfxav+WGNSwmnbH/Ad7odeXy/DhLS3QPciPPbEtBtSrql1rExSA8RSyThT+zvF2yKCvuZ4KM6KFVR87zyThTEwi1o3vg0APZ3Sv7Y9wCtTVh2O0MD3rVMETXRoi2NsN4efT4OFkh3VxqXi8aSCPHdCwigfaVvPWtPI3h7XHAyFBmoBvRr8Pww9qcZynBcHJwQ7OvPfFro3R0M9d8x/6xyY8woFJj9pVtFa2kAOHnl8tw1MdGqCpvye2RieYy6XdUOwjNScPG0/EWlA1tk+9GlTb154HY7Mx1bhxSGiufxMTNShUnPQnoAgqdUEfoZlTUzeoDBUJWSyHplNzEHVgaiDm+yzOzeFKj8bsq1Wouq+UG1QBlCDVC2K+yfLAlI+LxaMHL5KE5YmevunbFKV+W2lZ0/JrGU6LTo/HfGfpB+akzQdauHQrNL2rjIlQL70aK6Rv4+o++GpY2wpZNinU9SFQtNsC0rNyodqN7lpV5aCQLjo1U/cyf3dguHtnb8P2U/Hw5gI7hwuqSsZbYtKz4WBnA18XR3McI5rWwBqTUG/o6443V4RiA6eO/O3tkJaVZw5nKVSceC2bZvZW/1uBJJrUA9xd2K+rDhv4eUwn3M883cqBiK2zA57v2QzK5L/jaAyOnUzAt2vDjFExuLLsxHGdwOW4pv4e2MDBiLjKSyDg9dmF4yQrwiBC3Yoqoyyz0q6GLxJ8L6/DKst8SNzWTUDXJfVcOjrYIoXaru7USvbk7BzU4mK6yOTC+cTzFIbdPl2IAy8NRRNqusq5cS78Ys7f2R4FFLBpeXlwtjcK9t0Wc96DOVX04ZjOmMU/5Tp+udwiOqPQVh6f7z2JabQoRD0/BA40Vx/i/Hpnzp8rV8/HDTsev0U7DqWW3+vzxaji64Z61Oan3toSw4NratfUhzLjeziyS1RRF0Zvvi4HQqAEgeKj4BIByt/DYtah/BOXFMuPwKPt6uGV7k3KL0FJ6aYkoGu4euZ7N62FyYv3anPQaqVvd85JD29VF3YUnrb8Z5OfD7XgLDE7j35K6bXRNOHPt0cig/5qAHAh16a6LxycHPHCigPI5mBh46lEvMN5edVPKvN1IoVsTQp+dfzjvhPYHx2H/Fyjtq7mms9wXjuRGvq5pAxU59SS0sBj0rIxZsZmpOXma/e1mrYYkzcf0Y6rujnCk1YBTvvjl1Gd8MTcnQiNTdHue2rdIfT7ZZ2WVUcW5HxqNs6kFg5mLlQG8a+8BM6+PhIdqxktV9ZEwYYPjBWONawJkeRFCFQeAtu4CO7Ff3dh7cN9tUIrYfvymjDM3XVME379m9XC232bo6q7kzaXfcdf23CGmvF8boX7g9smf+TKcQMFbv+m1IAp5FcfOosdT/bHAK5I3/JovxIgT1AwP0DzeMS5JFSj9n9P+wZYd+wc5oztom3B/GLNQeQwnn6NApFHc3746Xhse7w/fg+NxqcUxO1pgXp3QEuM+GMjV8SnIsDNBeO7N8bUZXvx9qA2aODvjucW7kEk5+TdaOq/m/G/2tO4AO6r7Vzpvj4MWRwMNKvmg5+5aK6auzPCGc/dzFNeRg72PDuocEq7RO7FQwhYHwER6tZXJ5IjISAEhIAQEAJXRUDM71eFTW4SAkJACAgBIWB9BESoW1+dSI6EgBAQAkJACFwVARHqV4VNbhICQkAICAEhYH0ERKhbX51IjoSAEBACQkAIXBUBEepXhU1uEgJCQAgIASFgfQREqFtfnUiOhIAQEAJCQAhcFQER6leFTW4SAkJACAgBIWB9BESoW1+dSI6EgBAQAkJACFwVARHqV4VNbhICQkAICAEhYH0ERKhbX51IjoSAEBACQkAIXBUBEepXhU1uEgJCQAgIASFgfQREqFtfnUiOhIAQEAJCQAhcFQER6leFTW4SAkJACAgBIWB9BESoW1+dSI6EgBAQAkJACFwVARHqV4VNbhICQkAICAEhYH0E7K0vS5Kj600gOSsHJ5Iyr3e0N2189XxckW8wCBOLGmxZzQuxaVmIScu28K28hzY2QJMqHjh+Ph1ZeQWVF0Sxkqt2sj8muZhv5T11trdFI38PqwIgQt2qqqNsMrPo8FmM+2192UR+E8a65JFbcD4zBztOxt+Eub/+Wd51KgHrH7sFX2w5gigKMX9Xp+ufyE0W47YTcZh1Tw88t2A3GlpZp32jUM7ecxzRr43E4O9WYlTrujcqG1aVbkR8KhY+0NOq8iRC3aqqQzJTngQ+HdKmPJOz2rTeWRtmztuknk3Rspq3+byyHkxaslcrelNqph8NbFVZMRQp95aoOO28ho875NkxotHbSRFQN/hE5tRvcAVI8kJACAgBISAErhcBEerXi6TEIwSEgBAQAkLgBhMQoX6DK0CSFwJCQAgIASFwvQiU+Zw6Fxlj9oHoUvNbh3Mz7Wv6lHrtenuezcjGxmOxCPR2Qdda/tc7+lLjM7Dw2fkGqJGTI1dJXsip1bXhCamo5+0KTyeHCwUrM383BzvkFhiQk1+4yteOq39d7e2Qmpt/wXQ9eF9aXj5UHavj0sIyGrhbhLtgZMUuqPiyCwqYJ0ZuJS4lOxeFhIpmysvRHjZqyfQlXCZ55rBcXhepZ9VuUnPy4Gxnd9F2c4mkyvxygSmfpdWQo60tXFmHl3LmsjKsuudCLofPSFZ+/g15Pi6Up9L81XOUnptX2iU4sXwul8FE3ZzMtqbCXoxJNplkk4nHZba9UjNVDp6q7jKYT0unnhTVblwvs43nk2sauXpeoqzq+co1FDBc+fejluW7kcdlLtRV4cb8ssZYg+pE6/hYnfw/pkMD/HVnF+Vb5m7ruRSM+XkNBobUweL7epR5eiqBJD6YLT5cgPoBXlj3aL8LpvnT/hP4z+8bMPfhfhjWJPCC4crqwuzxfXE6LRPjp28wJzGoVV18NbQtar81B+ADVcK5OCLqlWHo8OVKHMvIRNSLQ9Fi6iKcSUwrErSmtxt2TxyMLp8vRURcSpFrlid1yWjasPYYyjoCH8wdzw/BtzuO4dOVoZbBbuhx02lLkFSsfNCGbEDkq8NR9TJWjT+xeC9mh55E8uThFyxLZm4Bgj9ciFcGt8JjbepeMNyNvnAyJRMhHy1AnnngpQ95bHFbq9r4645LP9tqQNt86kJMHtwGD7cKumCRft4dhdeX70PMRbhd8OZyvPBv5Dnc++NqplhygHJHh4b4aXjby8pNjbf+wad3dcGEZrUuGP4bPh8frgrFoReGWLUQ+37fCbwwexvLobePwiJNHdkJj7WrV+hxgaM9scno9eUynGT9+zo7XiAU8OLS/Zh/+BROsP+orK5chLqC68GK+ODubnBzKEyyoaeLNiJVmosH/Z2pGabl5CMzPw9udvbI44hLaWteDg44kZoBHqKhrxtsLTSibGqKkUkZ1GjsUM/LxawtxXHLkgPDeTrZ40hCGvoGeuP466Ph5mh82OLVdVsbbSQclZQOXzcnrVNO5J7us6lZCGTevC20KTVSPJaczjwY0JAWBjveq5wKr/o0H6ZzlNuBHFQ+qHErp/Jwmve4M564zGz4kYFl3j/bdgyLacVYEU5LBqMzxqjdWq4fS4/G4I1eTfEYNYNck2Y+LLgmIs5TQJcm0FXuyNaHgt1O4aQVZNgv65HIgUFxp8rrw3JfSov1cHbCbY2qsS9U2l0+7p+5BTEpGcWju6HnXwzvSG0hF7EZOZg0YyPu69kcfRoEaBXnbdIMlOapnF5eda4fK//xHRugbykDN8twTrTqfDKmE9pV9VK3mJ0paoW+iLuQf5FAZXASwEHMl+O6c3xegH/2nMDq0Gh8MrYrHGnmqeflZk7RsmzK0/LckQ1o6ujOJcpaPFwftg0f03NljliLS2uKll7asWJSnFOJQGXg0TXQB/+7t4emtHyy8gD2cbvgr2rLE/PT2NfdnKIlA+VZPL9fk2uPmr7m8KWFGdCkOqr7ucPFvrBPLS2cHknxNHX/sv4eUL8qPO7ppiXz7qI9KLCx5SAuRDvvWr2wjJb5szxWAetROVBM3IuVVV2zDHtvh3ro3bSkYlScr7pPOct7jT43/2fR1lCG5VGdf99AX0346cn4Ozvgl/0n8fDv69G5YSDWTeiDNtMWIy45A4ufuBXvLQvFgv3H0bJOVew/Eau1/O5Na2ImNYBAD2esiorHkB9WIys7R6ucro0CsfT+HnBnBxvw5mztIcqjqDx2LhFT7uqG19gRD2xp1NQbvTsX1b3dkZSehTMcFIAd0Qu3tsKHy7mVhWZoR5p55j3UFwMbVNUGDYN/XIPws+e1rNf198TKR2/RhHfIZ4uRykGAr6crIjmaZCYxtktjTB/RAcEf/KuFP0z/wNf/xuk3RyPApXAP8HkOCLLz8hBczRdhZxLUc39D3O/cn/xe3+YYzr2ns7Yf1YRQP5b7443h1ADs8BS5PM7RdDa5fLz5CH5YcxBZKqd6hsn7yd7N8MiMJOQVZGFcx8b4b5+mUBrnd9QmbGz0gEB/WgDe79+Cnb4r5kXE4IPl+5HAOvh0hFGDmcsO8JG/t+Kh7k2w6NApRHFawt/NGRP6tcCk9vVwmmHfXHUQs5lP5T67uzs2HDqNOzs1QHduxfpw42FMY5zq5TLX241oWFWLMiIxA5N41KGGD+7l4Gfu8Vj0+nU97mtdB4/N3Yatj/bHQdb5u2vCtLYXHOiHTwa3xq1kujziLBYficHYxtUxft5OuLs4sO6TseLIKfRvUhMz7uikmST/x3L8p2sjZNIMP2HudjzYvgFeW7YXWRz0vsC6eoHXlGz/dNtRTFm6D8kc8b7Lepq9JwrT7+yM4HLYW63M6/eYOtDDp5Kw3vYUxnHAoszGT7AOPmHe7HJyMfvgKZynVee/yw/g213HtOfrjpZB+Py21pqG+d2mw7BnedL5HE/4Zwce79wQLy/di7TMXLzMsj7frTH2nTmPL7cexRgK91dY/6doJfByssMX5BRc1Rt/j+uqlfksX6Dz1MI9mLsnEq3qBqB73aoIPZ2IJewX1CC+rF01DnTuZR+l3J/bIrHP9rz5vBvbyIAmNbAq/AxiafFZ83Bv/HdpKH7fexy2bK73t6uPL7nNUikMX6w9CM9bW6KGmyM6fb0SY9vWxbu0WmWzXX84gBYcPgu7TiXi++3HMIjl/M+CvVQobJHEAfaMncfQuUE1/DC8A5qyHZyj371/b8NyPk9d2c82Zf+VysHpzFEdyxqHFn99DsbUn3Lfrj2EfFaDzmjw7xvRopYf1h85g3BaU/c9NQDPLt6DOQdOcfrJBo90bIi3+zXjS5Gy8Dn7nWH1qmDx0XP4amsERjavicfm7UBVKmRf3t4Oo/gsrmSfsuZ4HIbzWXuIz5c3FY+jtBD+G3YKfSkf/r6rM2WQA3bEJOHZBbuwiQrNbS2CYM+pkSa0Fr7HtG52Z1Rby7oUbLBJ1FobT5mNgMl/8W8mAl77i1puLh4ICcLITo2w4fBpjGBnHnE2CRNvCUFntVdWEwY2UBpB3od344m+LbUO/Gt2FnFsqP2+Xkrt1x6xU8bg9wd7Y1P4aTy0eJ8m4FWRDp9LpiYODO/THP5K69b6ef3BtsHx2CT8dG9PfK3M8ewU/7dqPzY9PRifjeuBHHae31CAZVEwtaLgPsuHcMeLwxDGvyg2kntnbqYSqyK00awNd/dshpOvj4IfBdCinceRwfmfGJ6rNINZllzm31Kgq/xN4Z7gdY/0wysUWCoePWfqWnm6BD4wS/ggjG9bT0u2W6PqUJ3TH+wwJg1ui3s5ZdH0/X/R9avl+PzWENSuxnUQGktTLmmdGM17VCffhp3oTyPa4YmFe9Fq6r/oz84FBmPJgjmo+3t0Bzz4Lx+2V2aigPNsH9zWBrEcxE1keOWG/7ERsRTkQ+tXQVM/T4UFX4/thvEtaqLO23Px8Nyd+Hl4O9zW2pjX2+tVxWvs+Ed/sxKD2EG83685OlIzKHNn0ZZOsC1upcnvdZbrGXa4NWjleYJteTDbdv77Y1GTHetDf23WsnQ0LhXb1QCV7sjZRPyy7hC+GtYGByYOwUZ2um9yIKCMIwf58pPTKVlIyc7DFnZ4n1LwHaVJcVyH+nhv0S6kU9hPZ0f10pxteGNga2S/Ngo/bz6M3cdj2B5Ln9PVEi3Tj8JGcYBvHZu3PQLHE9PxEadV3t0Ugdm7jyH2paFIZ17X8nmfvPKg9qweYFljODBOY3+wLeIM3lmxH2HPDML9tGq8w+kKtb7gXEo2Qk37pI/GJeO3jWGoSmvAmZf5PLKDfvyf7VrJnli4GxsZd/TkkXiRz9e3aw7gQFQsm2th3soUgUXkWooWyW4/EY9X521DBq2LrwwIwXOrwjBn93Gt7nc+NwjfbjyEvzjgU24nzfhn+FzSWIndkTFYwRdIxb0yHLfwOfvPX5twim/+O8vnRpUtn31XONvSD+vD0C+4BjLfuQtHzyTio3VhUPPZrT5dpLW1GL445sG2dfDDuoM4EJ1gkdMbdxjKfHy8ZDcHt074cCif6z83YjutG0mcztpDAf8t87oo4hxS2aZ3HT9HpcGAOA7oVoaewHwOFg1v34E61OKfnbtDK8QJvgxmX7TxpVKKyecr9mFijybY9cxAyo5TeH6RsZ9RL+PKIxvFqlPdKli4OxIRlAcVwZWPUCcpZR7vR+E9oEsTDKQmO5jfjlwkody3nE/zYqXOo7Duw0b5QvdGmr/xw0DNpJk2en29dzC8acpdwspcxkVvSqN2oElr9Jzt+IFzbmAas/hgZOcZn6SaPm4InXgb/mH81dyNGrKNxcPdpKY/bq3jj8fY+fq4OqNJ7SroQu3r6TZ1NNPyOZrMDyWkUBPPhKuHC17gnN7j/ANHhpuocUUl09zMpLxpOn66VS3UYmfenvnPLsjTTPIWhbD6w2UUEI0CKETpHu3cCAs44k1guact24cOnDd14Ki5SXUKcwrZ+n4eFuUxCmy90xzTqg72c9CzktqHgjCJI2l9BBDJh6bBu/MRGhmHBlU8Ud3dFf7UVJUrYMetOQ6mlNP7wroU7CMbV0Vrzrum0LKxhQO3Nzna//52avZa0gZ8sOmI1hZ2Hz6D4+zovFkPZemKK3zaQ8S2+CsHh592bUzNwRGHucbg9a4NsY0DyzhOI5wmy9Jck3oB2nROMwr+ZmyP4RSCRqcIGCkoLWLe3V21QdMoasKZTEtZIqbTwtKBg6ZnOtbXFtR9TM1Mc8UzaPQt10/FpAafkx20aD1PLfPlLg35LA7Rns11p+I5zVPA1/SWMr1Cm/k/9/XUFsQNbVoDKbRkqamv4s6fHfl/GWd1d2cM5fMbwYGgWiQ1l1rq2+RQnZa80dSYR7Svb2onxWO4AedUUtSzs/GBHhjLevyE1q3DL94O9QRsjaYVkHW655xJsGhtmx+munyhTzBsefwNB8HKneFAUnPGx087bMsB7gOcg1fTN0qROE3BH0llJIbTj9/f0VmbXryfrOpX9zbee0M+S9Zl3ya1sIyWloc4cF9KE/vux/sjlgO8LWSi2nkCFcLizoZlnD+um+Y9tk09bZBTPIw6r1PDF91pCWhDLbxdUBWExidzoJyLCD6X79N6pl7z+gqf2aZUOCqKKx/zOxuemkv/a2ibUhc5ZPBhdKaWl5xpQEx6NjU44tV6St7INuBgEv7KLMX+jfPuuVwJyyEsrzV2d6GZ3Y2HNmjZy2g60QWMGijYmSfW9Navfxu0uT+9ItXcr5M2QWz0Ueeq+emLgLw4mGjJuXSVaEsOTpRz0MIbtHlle9PD567yqm5Uf8ppyeknRq/SP/Vcl361rH2XU1h+Q0EZXMMfbbj+QJm4lRvVqSFeoPlzDk3cmyxfq6pjVIG0Y6OHOzvZQ1xboJc4W83Rm8LWotnvf+xclBXk97DTmqnQy9FCAFvGqd1UoJnPsjhIS+FDrrtjFNxODlwPYaqveAp73SkBYKsnqHuWxbeWV2MpjcMQoFdNPy0lZYEa8NNaCt98DKVJsB478j0n40rNhatT4aIfWw6czOAYtW67Yb/DldPGAbDq2HWXRbbuHFDqroo+tVOKENTDlO13Yd5UOh60jumP3/TQU3iPU1tBNfwwvGE1eLkWlruw0Cwzo3BmX6GcwlF4jc+7RfRql4i+PkXN4auaSKF1TM2RBnFqR3fejkxHb4y6Z7l9l0y4M3feOKhOjO4zDkC+XHWAU4/V0a9+AAwW/Y85z6ouWW4XZWmkU4Pr0p2Bu0yMYdR1jQ1vVbtv1P3uJqbK35vtRLUda3Cq5ppwXYBad6Isn5NXUzPfF4WQ+tXQq7YfTfBGVsXz6kQFTt9RZK8eEPMiPMWnkLuynOprWlRUqqeI47SOCuOnPy88UwOhiuLKrSRqa9KPYWfwNRfT6H9zaWJSD+FEaoPnOVc6mvOGYez8XqfJTHOqblhHizkHpUbh2zk3lsFRVkuOvlqrRURsCBns5N6myfVlLvSyZ9jqXCynFtwpV7RwxsatXeCHGgQUdYUNwdJfmVLVXJw9TTWTezfV0nLjfLuDgy1qmLR/y/DaseqZ6LT0aXpWW8XUvJbRXK9dsroPNaWwnmavD2k6VwsBlSXChXPlXw9qhQn/7sYkmpM3HDyt5dtUvMIyaOiM/A5Q8A+q629ejRuktHuT+X1USF24UTgN+t9y/EmzWkwGzYumWPQo9MGR0dsWJ7lYT/VL3WkBUE7VxVjOpYXGpmqmRc2zyIelLabIhet3ojJrKpOK1IbyRjm9Y/huF9+RzXxHPHcbPuUrRqtQYzUX1BhU+1TRFGmFfBbMjpDNZxZpma/zoBEXGR1gnamFnaptfbMtwvLyDTg251hLW+9M1clv244gmJaIrVwz8Rw1bGM96+EtKVgeqzv186JPsyb91WULp3Yf1OAA6vMNh7S2oabolh86WRiFRdhyO9SzryVIxcEkPJRZ/D3OHT9+Swssu7c7HlK7HFT9W7YBdU+xYhsLUyTSixYlQPVRbEtzaYlT2+2OUXPfFXXuoveU6cViWVctwN40UFFTnQu45uI5Tkcqzf0eWhVsLQHozUXLoGVElhfUsX6NvXxxnryq5ve9OBieTVmknhu1iyOKZnvLZ1pL4ib9KB9NnXDSqV2/8Mf6IpiCae5O6hWMGVsOo3/zIMzi9rZmnAv6kHNqw4NrmRl/vyEMHy3drd3r6+KM53o0RVuakF7o31Lb8uTBRTHK+bCiFtN0YxY65gN11VjRevUbz/TKV1d1vUiFLXRqQd7Xd/fAxJkbUYXrAZRTJpu3x3Q1aQoqjsJ4tACmD18u0qhCK4JaqFHt1Vk499YYbX2AZRjL49JjsQxRtsdT14Xj37u7YTkXfimhpEDuoZlqzpiOeI4DqYe5KErtnx3HhUybT5c+JzdrZySeo2a/mXOEC04k4D6u0DWujQDCaH5/jQvo3rurK7y4AO82zr878YFuSBNyJOdF1cK69Y/1x6jf1pqIFmiL6B7i4rPl3N7zGbXeHjQrBlJI1p26QIOh16dORonCcuFoWu+h0i2eXjOyymV77/jtCs6vu2HHMXai1CJ/4iI2S1f8vsKGq0KpcphKVyygXuaPOS+7nvPHgVyrYsNVwd2pAZfMjWWKZX1cmFE9j3qKQTR/LuZz+sj8XZhPAZPF6QhlxUkll6LOsv4K4yvUxPTQxVMw+k/jDoV72X6cuG7Hi4P7umwvKemFlhz97nL5VtkvPZualtmYVosPuA4jJj4Nq4+dZX7tsYDa+6RLbvGyjNSSkeUxw/BUTU9MHdEJb3JR2IdUlqpQmw+mtUAfiJYLB8tEVNYts6mdGD2UJdaPz8t7XCSp1kPN5Fa4HE6//Mk+pTmVC/2+EjZNSxwMpBRF3RUdDzMd06VxtEC+v2wPpqzYC3+l9avdK0Xypcdw831zIGNBoAzyr2JP5Nx0aU5VohrN51GTdSNUNYpVW9pURTqygY+dsVlb/b7kPwO0rWRRHFGNa1bD/OIOlfUkmjp/4IirPk1u/Tg/rr+IQf0KlxoAKrO5cmrbnFqIo0zmyiyYqK4zff1lL6WdK1On/pIQJcxmc7GK2tI2moJKN/8l0fSryujNlfyqLFr+uSVP38aVyvJEc1tbJkfmrfnjELrJ0JKHGrWrKQW1al83KVlev9bjP/lwXM6vtNkz/4qNWpGfwTwp50gGNYICWD92OMmFKvbsFNpwsc4a7q33pElPzU+peS9V3iRtFwJNhazHYJrPnFmH+4+c5kjcjuGMW//8uUugE1d+b6E5P5PsmjWqwdXJCciiSd2L5bflICqFAwpVjzk0X+v5UPXQtXltHE9KwwkurNL91bbDdOY3V6nzdCpcJs8v9tIa/VfaxobU1u650g81ulcLP/U2q/ZaZ7D+1BY/XTs9wfUWqr0MqOvHXRLumMnyBlOLbMa1BKpcasCn2Cmnt0F1rvoVd5ZdtWsX8lVtNJXs1FoS1XZy2Y5TGU7xVmtHMlhW3R1KSEe3Txdw8HjHRQePenj9W/2gyyscXL/KwfToFrWv6gddlCUtiwvA9OdAlUU9n+bnj4y2cffINq70v7dZTW5XNWhTMM+2r4s0LoJyZVmVVVqV7WJlVdzUs6IWTKlwyqlzpYUqJipdNTWnrHZqLcLLy0Mxl4vRol8bUeqzpzMo/q1+qONprv2ZxsWHV/uDLqosKl8qz8qpPkmtI3Lns6ScennMMg6g1fbaYdxZkZFrwLd8Vl/mTg7Vht34rKmpBdU3qS3BykqlmKpzxTWX5cw0MVeLCZUrrS2l8JoKy9sZhy16/bhGm19ffH9P7Z7L/ej0xTJsffJW6N+Xe59luOJtXvWfjrTeuZqYqKnYxZGx2kLQ28lEbQtecTwe41vW1raTqjpWz7Z6wY/OVXHUzzPY32Zz/lZvCyptSyaql1B9hMqH2s2jZISaxuv9zSq05WDnGy7CvRKn2snVto8rSedKwpa5ps5+CL40i12u0xq8qYK1Ho614ELoPev5l4hCdaCqI53EFcHFnV7hur96M5NlPtR9lu5S56ohPMSGVdzpHYvub3xgjQ+t8vNgWYLZkV/MKUHua3/5jC4W17VcUx2t2ndv6XLYKR2nMDc7PjQr+ROMyiXmF4a1vE8NYHZx0ZrZ8UHVXTwXjS3kNjfd7QiL1g+RzM4ZCUZBp17cY+nUoGqx2g5VzJUWrliQ636qhKtlW1KWG+di9RfEaaCJ3DOruweKtB1j+9A7Gz2M5blle/S1mPtTnbJ+PoMDpv9MX48n+oWgT5A/Xli0GyHc/ql2i5S3U9vY1J/uLMui/FQb785OU/3p7gUu8FPucsrqzDUUzg7GZ1YNfi2d5fk93B2xm9uUvhzdCQfjUzCTWx/v54K00gbTlnGUxbEaIFu64n2SUmKGatYVYyhfF+Ct7o21E0uWlm1N9Xn6uR2FoVqLpFxx3vq5Umbq8aVQflQ6PuKC4d0xidjDgcSsh/po95X3h54vPd3i/afaQTOKg37dqetqOlA5vY904ojNyb6w/1Yc9XM1OHDFxZmouNryZVjetPi9y90qC4/F4BC3TL5Ey1dFcGUu1K8F0iCuJK/KOe1AT+driUbuFQIVksAD1Hhz+M6GJdzTu5vWi+5c/fwk9/dXZvc9F+NO4VaxaZxXV9Nxz7PTfol74CurU8rM6ReG4BlqlJ9zZ5AaELw3siOG09pWmd0s7rD4krtm3uVCxerc2TRtbHeMrCBMrFqoP6rmli45v1SZm6aUvbITeKR1Hag/cUYC2lvuhrQWHBYElDb/DV/5LK6QQGtu3/3xCk3thXdb9xFnscQJASEgBISAEBACFYGAVWvqFQGwlMF6CRyKTbHezJVjzuK5JU53kVykqO+j1v0q43ci35ehXFpWHqSdGFuAvrddfQsTIxPVPqzNiVC3thopg/y04xarqfrbxsog/pstymCa3tRK7QV8/4E4QL15UbnBfPf8Js7NH+PLgyq7a873K3i72KMTFyAuPnK2suPQyn+PaUGy+hYmxiah2oe1uTLf0mZtBZb8CAEhIASEgBCoqARkTr2i1qyUSwgIASEgBCodARHqla7KpcBCQAgIASFQUQmIUK+oNSvlEgJCQAgIgUpHQIR6patyKbAQEAJCQAhUVAIi1CtqzUq5hIAQEAJCoNIREKFe6apcCiwEhIAQEAIVlYAI9Ypas1IuISAEhIAQqHQERKhXuiqXAgsBISAEhEBFJSBCvaLWrJRLCAgBISAEKh0BEeqVrsqlwEJACAgBIVBRCci73ytqzVqU6899J7AqIgZta/pa+FbOww2RcbiPP+d7PjMH435bVzkhlFJqw8f34NUV+2EwAIGeLqWEqFxeC8JO43v+7vjEhbvRs35A5Sr8BUr7yZqDOPrfYWjw3jw817vZBUJVLu91x2Lx17iuVlVoEepWVR1ll5m+DathbEhQ2SUgMVcIAmNa1kbLat4VoizXUojjicYftant64bHOzW8lqgqzL2/7YjUyuLv7iJMTLWqtxNrqmQxv1tTbUhehIAQEAJCQAhcAwER6tcAT24VAkJACAgBIWBNBESoW1NtSF6EgBAQAkJACFwDgTKfU1cLb5Kzc0rNoqOtHVwd7Uq9dr09cwsMSM/JhT3TdC+nNC+nDAYCSsnJ04J6ONjD1tbmcm6TMEJACAgBISAEShAoc6GuUvR5ZaZFwhRaStLTjelQH3/dWT4rBxeeiMeIL5ZgUEhdLLqvu0V+yu4wKzcfX2w/iiquTri/dZ0SCaXl5OOuv7di4e5j2rVGNf2x4qHeqC2rj0uwEg8hIASEgBC4NIFyEeoqGzZ2tqjeKJDfJs2ccr0qhVh5uVtq+GLfS8Pg7eRQXkkiLS8fL8zZhuDq3qUK9fH/7tAEerO61eAX4IEN2yIw9Kd12PvMgHLLoyQkBISAEBACFYdAuQl1b0dHhN7dDb7OjkXofbQlArO2H8NtIbXxeq9g3PfPDoRFJ+DVIW2w7vAZrD9yFre0CMLS/Se0+8b3aIrHWgfBxsYGOXkF6P/nJiQnpMKW53d2rI/nuf1EXWv/9XI0q+IJd3dnbA4/iycHhODr5fvQjQOLTweGoOd3qxBS3QcJWTkIO3Ue9s72mDW2G+5gfLlZeXDzcMIC5tfHlN9nl+3DukNnaGUAOtSriq+HttbSHPzbBuTSrF+vqje2H43R0n7r9rYYWCcA/b9bzdGMDU4lpKH9tKVY/kgfc3yqMFtZtuY1q2D/f25R0aLJ8Tjsi47ldEUuvMpx8KGBlQ8hIASEgBC46QmU00I5G2Tl5uL5xXvw2Pyd/NuFx/7dhQyap5/gi0CSee2zlaFYEHkOc7ZHwNfTFUPrBSAiLhU7T8bh103h6NO4OsPn4T9/rMcfB6KRW1CAbj+uxqbQE+hSvxr8vVzxyj/bMOPwWa1Sdp6Mx9zdkfhuzQGcpOCOzczW4jocl6xdD+XA4YsNYUimAHdxc8LOo+fQ+P1/UZvxOLo6YFPYKby4VL2Mw4C7OND4jC/maFTDBy1q+eLb9QcwZd0hYzynE7Ai/DS2nkpAm6Aq2Mfv+35ai2wOOLo1rKpNNbg4OaJPk0A46FYKU7N5ggOUSf2aawOBdM6rp/CFKFV93EWgm/jIlxAQAkJACFwZgXIS6gZk0RQ9b99JzNoTxb9I/L03Ctn5+XBxsMP/+OYmtZhu6JfL4OJojy+HtyssBVXY925vh6kDW2H1o7fAleF/2HIUq/lmsB1HzmB0r2a4u309vNi3GXINNhj350bkm+bs82GLc1PGIP6/t6MRhaWmDjOM5hgmuKoPFt7TDZsf7gtHasZNq3ph9tiu2PZIPzhSQz8Um4zw8+mYyUFF18aBeLpbEzzatTHsXJzxJt80pTRq5bwcHbD8vh74YUR79AquhQwK6JyCfLym3rrE5PzcHfHBrS3hzrxbuucZ3z3Na2If0wmeuhDx6Vn4aEhbyyByLASEgBAQAkLgsgmUn/mdgvAohWtx87vKad+6AejdtBZWH4zGY72ao6G3q7EAyiZNoRgU4Kmdq1XrrjTjRyak4FhKJoW0DWasPsC/UGNAJbXTs5GarVaTG1Db16OIuVuZwm00ya6C28DDpXB+3YMC18u1cGrAg2sAcin4k6g9K7fp0Gl0Caf5XbtfDQwMOJKUwW8bONjbwpl/yvl4OqOA10zjCu26duECHx9y+uElzrs72Nlg9/ND0JIDC3FCQAgIASEgBK6GQLkJdaMwLD2LX+8+ToF+koLRDm8t2Y1OfEf5oEbVzIFjOGcOvroyk+b6XJrqG3HhWU2azGFjwBND2uO1jvUY1gaxaVk0yxvg6aSKZQN7CsqijsK2qEfhGS8Uv6bOvbS4gFu5an76mI70MeB8Rg4yaV4P9vPQ8lAYibqs7rKMSR1zKEF/Nddv6d5cewjvLNqJ9hzUzH+wF6pzlbw4ISAEhIAQEAJXS6CchLoNEjmv7ff+AiXfzK51TR/8PbITpnB+XWnVeyYORsO35+E/nBsPm3ibOdxLvL6ci9TC41KQTNP23W3roTcFYbNAP3y5dDfS6K8E/l+7juHFga3RivPUpTpN1lpkwDIzRQRx4d2NKbh70KS+bH8UnuFiOgfuI/9121F0bhmEzffqW+Ms4tQOjefuHKSA8+hnqdHf9/c2fDWsLTxoqtfdd+vDkJtvoGYP3DF9o+6N3+/qItvazDTkQAgIASEgBC6XQLkI9f5Na5SanzpVvPDjriiEUDN/nIvGlGl+Ilepr+PCs593R5m14K4UqvtOxHGuOhfP9Q/BY9zfrtymJ/vj7hmbsSkqlvPVDniwSyO808f460H9m9REPd2Mz7DVaFrvH1wT7U2/VNaTq+Dr+Llp8agPdV6Pq+V1p85rVfGAHYX4uod64SEultvGdAw0+Q/jD6P8NKaTFrQ7F+ll09xvb2M0v7fhivoMpu1gS5M8TfovDmiNLZz7V1MGlN9FXEjtKmge6FPET50U1+hLBBAPISAEhIAQEAKlEChzoa4szsvG9yklaUuvYPPJy90aQ/0pt1TNYVMQTmgVhJ7cJlbcqQVqC+7rWdxbO192f48i/p05V22Zj7lcIGfp5nD7mqWbU+z6j1wEV5r7Y7RRuOvX/suFdFxVp5/i/T4sm/orxS0ulsdSgoiXEBACQkAICIHLJmBULy87eDkHVFZs/a+ck5bkhIAQEAJCQAjcbATKXFO/FiD/anPW+rz1tcQk9woBISAEhIAQqPgErFtTr/j8pYRCQAgIASEgBK4bAavW1K9bKSUinON2v4h4bg2s5C4uPQf1fCs5hIsUPzopEy5q10Yld8mZxhdLZXARrDw3xsag3pKpnPoWJkYmqn1Ym7Ph/ulia7KtLYuSn2slkMY3351NzbrWaCrM/TX5GuJ8Q4EwsajRhv4eSOSLluL58iZx4O86AHX4FsrTfMlVNt+GKc5IQLUTEeiFrcGJA+DaFrusCq/cuCMR6jeOvaQsBISAEBACQuC6EpA59euKUyITAkJACAgBIXDjCIhQv3HsJWUhIASEgBAQAteVgAj164pTIhMCQkAICAEhcOMIiFC/cewlZSEgBISAEBAC15WACPXrilMiEwJCQAgIASFw4wiIUL9x7CVlISAEhIAQEALXlYAI9euKUyITAkJACAgBIXDjCIhQv3HsJWUhIASEgBAQAteVgAj164pTIhMCQkAICAEhcOMIiFC/cewlZSEgBISAEBAC15WA/KDLdcVpnZH9ue8Exv223jozdwNyteSRW3Ce7zkf99u6G5C6dSZp+PgevLpiP95eus86M1jOuXKxt8WRl0fg1u9WIiwmqZxTt97kVDuxmTjdejNYzjkLruaNg5OGlHOqF09OhPrF+VSYq3/c2wNjQ4IqTHmutiBfb40w36o6KHHAO2vDBMMFCAxqXsvqOu0LZLXMvTt9sUxLo2OdAGx98tYyT+9mSGDSkr1Wl00xv1tdlUiGhIAQEAJCQAhcHQER6lfHTe4SAkJACAgBIWB1BESoW12VSIaEgBAQAkJACFwdARHqV8dN7hICQkAICAEhYHUEynyhnMEA2E7iakl+Gz9sjBD4NaZ9ffx1R5dygTL3eBxGfLUUg1rWwaJ7u5dLmhm5+Xh6wW7U8HTBG/2al0gzt6AAD8/bhcWHTiMPBRjcKBBfDm0LTyeHEmHFQwgIASEgBITApQiUuVDXMkDJ7mhni37BQXCwNQl1XuhY0+9S+btu12u5O2Fkq7poH1TlusV5qYgy8vLxw6ZDCK7mU6pQHztrK2bvjMTQFrVhIKMZ2yPg5uiA/93e9lJRy3UhIASEgBAQAiUIlI9Qh40mrKbf2Qm+zo5FMjE97BR2RJ/HbY2qoX/dAEwPjcaOs4kY1bQmjp5Pw55zSbizaSDun7sTGXkFWHR3V4RU8YSNjQ3yCwxYfiwW98/aDH9fDywY0wl1fd20axNXHkQND2cMqFsF/X5agx/u6IzqvK8KtWblXlodhjrerqjq5oTxMzZhRKcGeK9nML7ZfRxTl+/Hfwe1wZNt6sDVwU4Lv0vlaeYWZOfmYfE9PdCymhdsmYcpGw8jm8J7WMPqGD59A/y8XfDv2G6o7eGCl9ce0u6NT8vGU8v24f3ezeHqaIxPXdh3Mh63cpvZ/Hu6M44C1H9vHjYcPafdIx9CQAgIASEgBK6UQPkIdWqhmRSGjy4/AAcH4zS+HRX2b/q2wND6VfHS7G2YsSkc0a+OwsN/bEBjatOf9muBqWsOYAFfnPItX4qR6+kKJKahzUcLMH9CPwzhIGDUn5swb08kfKp4IexUApp9MA8rnxqErjV98cnKfXCxtcXE7FwyMWBXXBq+XLYXA0Pq4sGQ2viOcWfl5CIzv0CbFfiBacyhgE7MyuG5AS/9tQlRfOmE0ppfWXUQHy7dAycOADLt7NBm6gK8N6oTXuzcED9sDMep+BR8wFTymd7puCS0+2QRoiePwLxjMVrcSTl5mBNxDlM4aHBFoVDf+MStcKIFI54vQvkP9wqfS8nAuI4NrrQOJbwQEAJCQAgIAY1A+SyUowDPojb799oD+HPlfvxJATp9Zajm58X5449GdUR8ehY8Js9AFueZp4/sADvNTK9M9QZ8NqozCiYPx4GXhsGZ/t9tPYL11HLn7Y7ExFvbIOHFoTj932HIYui7fl2nafCqdA6cx5/3SD9kfnA3mlVxBw0G/K9N7mvxVvF2Q96HdyP9/bHUyO3hT809/yN1Po4atT0OxibhZHIG3l28G+2a1ETK66OQ9tLt8OMA44NFe8wDAHdq85GvjUL+B2PRkfPimVnZyMnPR9hDvbU0G9B6cPqJ/vB2LjpXHuDqBFX+B2dvxyxyceKApwXfUCROCAgBISAEhMDVECgfTZ0583Fxwr4XKRAtBJt6FaNydzWtgTcCfRBxJhETejRDiwAvzV/7oAxuRs1bmdsDvVzgwjnnw9SgDyWkaQLzk+V78dnyPcbwNMdHJ6QijVYB5ar7uOH2RtW1Yxsl0TV5rgYKxsNqXtSbOUhwtbXT4q1KYa1M6srk7kIhn834zqZma+G3hkXDcdLv2nE+NXnlIlPVMAJwtLfn4jZ77d6avu7YRw3dFMSUphasyIe6vpNTC0GcDpg7riuSR3VA8Af/4t4ZGzG08WhZLFeElpwIASEgBITA5RAoJ6FuFKRu1ET1OWrLzM0KO02BngQvzrd/vz4M97ati24U5JrjrSnU4pXLpak8n5q8t6szBwfGufn3RnbEs1xFr1xYfKpmTveklq2cWpxX6ChFtWwYBbIS8pqgNwcwGC+bz40HLmq6gBJ4cLv6+GdMZ80zMikdiZm5aOVn0v45ENDX/2lJ8NzsTMdqIZwamOhOHXb+eAEe694MXwxto2nxni6Omgn+DOfgZQW8Tkq+hYAQEAJC4HIJlJNQN1AIZqP+23OLCLaGtXyxZUJfPDRrC6pTSz74whDUeHM2HuOq8NDnBpm13Hv+2oyf7+yCFxfuRTLnvMdwAduQhtUAav+vzdvOLWPOOMg586mLduLOzk3QaXg7Y/kthGhJIEbhXtK/0EeJ4GYBnqhXwwdLaeqfQmtCCM3j9/60Gq3qVsXmR/uZ81h4V+GRu71x/vxoQgoG/EMT+21tNHO7HqIB1wJ8u+Eg1p9LRGZ2Po7GJaMt421Mc704ISAEhIAQEAJXSsBSlb3Se68gvFFDTaJgT8zIMv+lUdsd+tsGpKdm4v0RHWiid8SDPYJx4HQ87pq91aRZA7dzb/mI71Yhgv4TbwnBI+3qwomm+6MTB6NeoB/u4er29xfsxMNcXf4D93lbasRFMmlQM+q6tqy+LQW77l94hwprx4HB7icG4FZq6u8s2IUx369Ej5b1MO++HhbpWMRjEY0zzfiP39ISOdyvvnwzV8mrRXkWbs4DvdC2cQ3s5z71iOPnMK5zI/zDH165YP4t7pVDISAEhIAQEALFCdjQLGwhkYpfvrHnQ3/dwNXvx7H26UHoVstPWwDnwGXzxYVeDreD2XB44sDV52Xp1MtilLvSdAoUYv5X+S5uPFCX8gzGeO216xajgutUGPXTq8rJr7QB6lfa6nH7o/rp1bHcBSHO+Cttr/QKlp9etWgM+k+vTuNg/KOBrSyuVN5D9Stt6tfZ9O/KS6Kw5OpX2qytfZST+b0QwhUdqTlxtZiOck4taDOuiC8Zg6NpwV3JK9fX50qFuZ66WnxnNhDonqZvdclBjUjECQEhIASEgBC4RgJWLdT/4Mtkcke1hwdXvIsTAkJACAgBISAELk7AqoW6h/b2tcKXtVy8KHJVCAgBISAEhEDlJiB238pd/1J6ISAEhIAQqEAErFpTr0Ccb2hRAtycMZkLOj5fH35D82EtiU8b1p5LNWy0BT/WkqcbnQ+1UC7Ixx0d6wTc6KxYRfpqnY56hfOpxAxpJ6XUiFosJw6o6+dhdRisevW71dGSDAkBISAEhIAQsGICYn634sqRrAkBISAEhIAQuBICItSvhJaEFQJCQAgIASFgxQREqFtx5UjWhIAQEAJCQAhcCQER6ldCS8IKASEgBISAELBiAiLUrbhyJGtCQAgIASEgBK6EgAj1K6ElYYWAEBACQkAIWDEBEepWXDmSNSEgBISAEBACV0JAhPqV0JKwQkAICAEhIASsmIAIdSuuHMmaEBACQkAICIErISBC/UpoSVghIASEgBAQAlZMQN79bsWVc72yFpmQhqURZ69XdDd9PEOb1kROXr4wsajJxzs1xK7TidgWHW/hW3kP7WxscU/rOlgQfhoJGdmVF0Sxkqt28vXWiGK+lffUz9UJd7SsbVUARKhbVXWUTWa2nkqAt4sjxoYElU0CN1GsqkM6cC4Z5zNzoDooccA7a8M0DPPCojG6RW20rOZd6bFM4g8gqTYyZdk+hMUkVXoeOgD1zPy2IxJbn7xV96rU36qdWJtQF/N7pW6SUnghIASEgBCoSAREqFek2pSyCAEhIASEQKUmIEK9Ule/FF4ICAEhIAQqEgER6hWpNqUsQkAICAEhUKkJlPlCOYMB8Js80wTZxvRNT9jg9jZ18PPIjuVSAQtOxOO+71aib7Pa+Htsl3JJs6DAgCOJaXC2t0MdL9eLptn/1/WIiknEisf6I8jT5aJh5aIQEAJCQAgIgdIIlLlQV4kmZuUqGQ74ehi/TTnJcXY0HZX9VxNvVzzVpwWaBniWfWKmFM5n56LpO/MQXN0bBycNuWC6H205ghX7o7Tr2RwIiBMCQkAICAEhcDUEykWoAwb4ODvh6HOD4FtMkC+KiMHOkwnoGOSPAQ2q4pd9J3AiPg2DmtdEVHwqwrj9qH1tf6w/FsNYgNHcltXOtOWmgGaAaTuO48z5FNjb2mIw9x93q+WrcZiy7hBqerjAz90ZmyJjcHtIHW1cwe2nmnt/Qzjqershu6AAoWcS4cb9hs93boTPuOUpKT0LVahZP9uhARztjTfMP3IWm4/HQlkeOgRVwaimgVo8KpPtHTQAACWXSURBVHx+XgGC/Dyw/UQc82GDhzs2pGbugqlMAzYGJKZn481VYZjUozFcHeyMGTB9roqKw+R/d6KWryeiWQ5xQkAICAEhIASulkA5CXUbKFP02uPx8NCFGoVfrzr+CKGAvue39XBxtMfWZwZh0uxtqEJhO7l3U7y1bD8W7DsOb1dn1KJf9Pk0fLhiP9Y8ORA9a/vh8SX78O2qUE0TTqU14Os1B7Bp4hA09/fA60v2IMDRAbHpmbBxsIeXvyfeWLQbA1sFYUyzWvhw+T5kMU/+FOY5FMrnUjLw9YZDcOfgIC0nF3EpmUjOyMG7/Zrj+70n8Pgf61HbzxN2tDhMXbkfs8b3xagmgfhkzUEOKtLgowYQzg44zEHIT1siEP3qcCw8eEqNZ5CSlYO51MSf6tqgiFBPoSb/2KwtuKVpLeTlG0SoX20rlvuEgBAQAkJAI1BOC+UMSKZgG/nDSvT/33LzX2p2HrVpZ3w0vAPOJKWh9pt/Iz4jC9+M6Qw7ClcYKEEpFF8d3Br7Jw7GVmr6DjY2mEotfOupRE2g39+3BQ4+PwTbnxuMlJw89PxxjblqY/kmqI3P3ob89+5CMDVppTVr6r4KwbirUYs/+cpwTQCD894+FP6RLw/D2ddGARx8bImKxXEK94enr0enhoE4+uLtNKMPhcGOb5v6dS1yqeXbMD/OlPT7OCAJf2Eoujaohgymm5Wbj7WP9tOmG5QWv/fZQbRWFJ1uGDp9A5S1ff7d3bRw5ryZSyAHQkAICAEhIAQun0A5aeqAFwXab+P7wIsauXJqit3DyUE7vpfa87dbq2EHTexPUkh3r+mj+WsSmAHb1PTXzqtSCHsyniNcUBaakMrLBsyl+XvprmOm8DY4H5tE4c45fLqGVTzRtabRHG8KwHRVynQU8P6mxWsOHED4MS/+Pm7aJTtaEXyp5WfkFyA2JUvz20MzeeDb//DYoI0NsjggCaOGbmAenDkYcHUylivAzx25HAwUnRqn5C7mkmlZ2Hz4DFqwbHf+uQkHo+O0EE/P3YGPh7YxDkKK3SOnQkAICAEhIAQuRqDchLotBWW3QO8Sc+oqc0sjY7Ej8pyWz+83HMZDbeshpKqXOd+pmcZ3LyvNOJ9/Hk6OHBwY56bv7N4U9zWtYQ6rDlzsjcVSwrbQGQWrUv51V9RMYYDluR7M2cHo27FRIN7u10K/Vfuu72kcBChtncXTnB2PtcGI8dT0qcdW6KkWxOVyQLCbwlz9aZP1DLb04ElMYjrBfoVh5UgICAEhIASEwOUQsJR6lxP+6sJQnqr545Cf10EJd+UozzTB/fugVnhx3nb4uThh2RO3oscnC/EYtdUND/fVtGml07+/+gAKOO+9isI/iRruwOa1OKfuD393F8zYFI7+NbwZfx4embkJ/ZoHYeHdXUvPp5LrKmHNqXwUFbaaPDZd1b8a+bpzLt0dGw9FI7J1kLY97YEZm+FNk3rUMwNMcVjEox0azx1VWRlpEufmZ4ZGYzgHH06mhXcBro4wTL1HTwYDflmPZaEncHjySDTiSn1xQkAICAEhIASulEC5CHVPk2k6havDLeXoWWrdjy/ei9M0pU8c1BZtqZ3fwlXqayjc3lIrx7XAnI/nIrKxv6yhSduA1nUC8EqPJnDhnPeGpwei66eLMe6XtZqmHMQV5P/c1UWb5/aklq72h+tOmdQ9nezMfs68X9fCVRhnmtudLMI70xLgTI1fpXOI8+ghnyzChD820vhugDunANY92Itpcj5dWQP4i1+6c7a1h5vyozz3pEm/a3At7D9yBg//sQF9Xx+JKvZOetAi384U9p5MszDHRS7LiRAQAkJACAiBSxIoF6Ee/froUjOi1sIpVzCwFdxNgn8WF8lljehAjd4WY6P4M5BUrD+nNt+EmnEO57hreDpDzYEr19iXK+JfG4kYLkxz5GK1qm5O5mvRk4ebTeIq7MBa/oh+fYy29U2dh784lNdNGeB52KTbYG95zkVv+nW1De3AxNsQw61pKkNV3Zwp8I337nqyv8oiV/UbUX43pDVyB4fAw7R2YPX9PZBGKwXHJfAvtlCOt5ndnyx3XkFHMwfzBTkQAkJACAgBIXCZBMpcqCuTtie3el2uU/vC9b3hmqLO+9U8dSBXyRd3ai7bldptPceS5mqlJVs6B2rqDhb5KH79UufKbB7EvefFnb7YT/dXmr2Lhb7tyAGIL6cWLuVUOVjSSwWT60JACAgBISAELkigzIX6BVO+jAtfDmuHtweGoAH3qIsTAkJACAgBISAELk7AqoV6bb4DvTb1XnFCQAgIASEgBITApQkUTipfOqyEEAJCQAgIASEgBKyYgFVr6lbM7abL2pfc/z839NRNl+/rneEo7rR4iwszlRv9+6brHf1NGV9EbDJe6RWs5X3Sor3aro2bsiDXMdNHziXh6S6Nr2OMFSeqqPgUeXZM1ZmUaXw5mTXVrg3fiKZv3LamfElehIAQEAJCQAgIgSskIOb3KwQmwYWAEBACQkAIWCsBEerWWjOSLyEgBISAEBACV0hAhPoVApPgQkAICAEhIASslYAIdWutGcmXEBACQkAICIErJCBC/QqBSXAhIASEgBAQAtZKQIS6tdaM5EsICAEhIASEwBUSEKF+hcAkuBAQAkJACAgBayUgQt1aa0byJQSEgBAQAkLgCgmIUL9CYBJcCAgBISAEhIC1EhChbq01I/kSAkJACAgBIXCFBOTd71cI7GYMvvdsEn7dGXkzZr1M8vxY54bIyM0XJhZ0Px3SBssjYrAk/IyFb+U9tLezweQ+zfDN9mOISc6svCCKlVy1k2cX7C7mW3lPq3m54MUeTa0KgAh1q6qOsslMGH+wo4a3K25rElg2CdxEsc7YexKR59NxPjMHj3RqcBPlvOyy+i0Fl3IbomLRq0E1NPZ3L7vEbpKYp64/hNTsfJxgW3mqa6ObJNdlm827ft+oJfDZ2oNlm9BNFHtwNW8R6jdRfVWorAbyt+mbVPGsUGW6msJU9XAy3yY8jCj83QqZ1PVxlXZCLD6uRiZuTvbCw/TEONnbmZ8dObBeAjKnbr11IzkTAkJACAgBIXBFBESoXxEuCSwEhIAQEAJCwHoJiFC33rqRnAkBISAEhIAQuCICZb5QzmAAWnyyqNRMDWpWEx8OCCn12vX2XH06EU/N3IyeXCz21eDW1zv6UuPLySvAoogz8HJyRJ96ASXCxGVkY/KKAzDwnw3/KRdSwxePt6tbIqx4CAEhIASEgBC4FIEyF+oqAwfPJGgiy8/NBTZG2aXlKzEr91L5u27Xc/INSE7PRipXPZeXS8nNw4gfViO4mg8OThpSItl5x+Pw3fqD8CcXWw2MAeezc0WolyAlHkJACAgBIXA5BMpFqIMi3dvFEbso2HydHcz5sqcg23jqPM5S2Lbn1oA63PO3NzYFEYnpaOLrhvScfJxMzUav2j54Z1MEMvLzMa1vc7g6FK7CjE7JxOtrwuDn4YL3ezWBna1xRuGfIzFMyx5dAqn5Lt6Lpzs3wMdjOqEWwyk3P+Icqrg6ohpX/r6xMhT9m9fC3dTiV52Mw0/bI/Ew9zL3pNasu2QK25fXhiGb2vfnt7SEq6MxD0uPxyKXA4YetXzxwvJQ+Hg4Mx/B2m3/Hj2nfadl5+Hv8LO4vUFVONoXznjsPhYLZhhHXxkGB1O+7SxHPXri8i0EhIAQEAJC4DIIlI9Qpw0+v8CANdHx8HBwgIHauhJtg+tVgTOF3IRf1yGA+6gPPn8bBny9HI5ODtj5zACM/3sbFuyLQoCnK2IpGJGVg/nbj2Lpw33RhoOA9zYexmv/7oADzduZObmYsSkcG58cgDqMa+RPq1Gd21LSaQ1Iyc5BUKA3XvtzIwaG1MHi+3rggd/WQW3RSMnM1l5EMn3LEXzOPbo7jsUAzO+MrUfwwfCOmMQ9qvMPn8WDv29Aal4ecm1sMXvTYcwY3xsD61XFwzO3ID4pDU4O9khi/tS98/dEYf/TA/HM/B08B04np2PC31vQm+Xzt3c0V8vu0/Go7uGKJxfuRujpJDT098C0YW1R3b5wi5E5sBwIASEgBISAELgEgUK18RIBr+kyhbgSrPf/uBojv1mOUf9bhhH8VhpsOwrniQNbIeJcEup/uADn0jLx6e1tEeBCwaakP4XiuA4NkP/OHZg1oQ8SUzPwBbX20LgUvDxvO/o2q43E10dh67ODNeE55q/NlKu8iS4+NRMPdGuCFc/chnocGChXaP3nQMNQgIjJIxD639uh3iB1Oj4V56aMwb6XhlGBtsHKw2eg5r1HcYDg4+WGM0zn3OThyGH0/5m1FVnU2lUG85nenEduQfq7Y9Ek0A9nWJYsmt4jJ96mJdg4wBNJr46AP60Vlu4831SVzPKe47ePiz3m7jmGezmQEScEhIAQEAJC4GoIlI+mTlHqSe37+wd6wZ1ma6NgtYEHX+yg3CtdG+MXasqRFIYPdAvGyOCaxrKogPy7vUVtbc65b92q8HR2wja++WpbfS48ozDdSM265jv/MJwx1h3UqtMoUJWr7eeBzwa10o7ncv7amLAxnFqaVifAC4HuztqfF+MNquqJAGr36s+T2n8S44lKzEBeXj7OnE9FUw46VJqZnAY4HpeMo0npjNsG7gzbOsBDM8k3oRk+KjYRNEwYnRqYGBM2eRR+LZrQV7unJqcEChhv8McLsXJ/FOIzO5UYABTeJUdCQAgIASEgBEonUE5CXU0d26IfBZ6vc1FtVWVr19lknOBcunIzaF5/+5bmmqDVPPiRT6FqdJSU/O9ALdqRf8pNvCUEQzlXrTnlxeuu9sZiudLUX+iMUtb4aRSztsWErb3FuTF2G01jV3F0a1YL7/Fd0GbHAPW8jNq/WuRGRV9zap2AWYhbHJrvMx1QhmPKqlAMalIDY1vWZsqMw5Tf+IwcEerFgcm5EBACQkAIXJJA+ZjfKWnTcnIwiqblW//chFv/MP49uXy/ZiofP2crtXYHzHqoH7XiPEyYs92YcZMEfmP1QYQnpOHNdYeQnJWFPlzQ1rtOFdBmjp83h2um83PpORj98zq8tyGcWr2p3Pq3dqqf6GJdfevHpvAlvgxowAV7/tSk9xw+jXjOmTtyYds9LMNj83fCicfGOEqPx1ET8AYk0IT/S9gpbZGdnoS6tOzgKTz3z3Z8zB9bmcx3TUedTUDbutXQiGmKEwJCQAgIASFwpQTKTVPP5fzzmr3HmT8lXCkEaZY+FeSPZ/MLsP9ELJ7pH4LRwYH4kXPki/efwEc0x+tBkymwm747V7uvA4XeM10aoxbfZT73gT6YMHMTWr0/XwvbOigAX9DcbqMJ0+IoVJrKTxfu+ndhOO1y4al2pKYNVj5+K0ZzYd2AL5cxDoNmtv/2ti4mLb5kPPpYQd3biZr41kOn8QC3tg16+w4EWCyCmzqiA17mLx49P2Ojlq+Q2v74YXRH0/a2YhmRUyEgBISAEBAClyBQ5kJdyVfDx/deNBufcaGc7pbe30M/xIYj3BLG+z8f2gYNfd2htpU18XM3C+1hTapj2BujcCA+BV6OjhT0zuZ7De+PNR+rg+F1A2D4pDAf598aU+R6/JTRRc8trodwoduR54cgIimDMr0AjXwKf8XqJBfZWbq/R3cC1J/JbeG8eQa35uUa8uHpaDkdANwXEoR7aHqP4kK5bE4xWJZNv1++hYAQEAJCQAhcLoEyF+qXm5FLhQvk/m/1V5pr7l8+vz7WkFvlrsYZ97QX7q23jEPNx9e7yngt45FjISAEhIAQEAJWLdSnDGyJx7s3RkhVL6kpISAEhIAQEAJC4BIErFqot+KWM5R8ZfoliiSXhYAQEAJCQAhUTgLltPq9csKVUgsBISAEhIAQKE8CVq2plyeIip7WlxsOY27oqYpezEuWLyohFW+ZFmaO/n3TJcNXhgARscl4xfR7BZMW7uULnoou6KwMDIqX8QhfhPU0d9nsPZUAaSdGOlFckCzO+gnY8JWqpe3ksv6cSw4vm0Bmbj73ypffr9NddsZuUMAqfGNgAfcdCpPCCqjJH1NK4e6SlCzj2xgLr1TSI+66qc63TcbzHRPqB5vEGQmodnKKu3XEGQk48K1jVdlOrMmJULem2pC8CAEhIASEgBC4BgIyp34N8ORWISAEhIAQEALWRECEujXVhuRFCAgBISAEhMA1EBChfg3w5FYhIASEgBAQAtZEQIS6NdWG5EUICAEhIASEwDUQEKF+DfDkViEgBISAEBAC1kRAhLo11YbkRQgIASEgBITANRAQoX4N8ORWISAEhIAQEALWRECEujXVxk2Ql21nk7D59PlL5jSSP1NbmtvDN3UNn74B60/Gl3ZZ85u8Ogxp/Lna4m7J0XOYvu9Ece8bcr7qeCyeWrIXb61lXvlynytx7288jC2nE0vc8mdoNG7/dT0KLvI+qAlMszT38ZYI7I+9sW/8Uu+x+vdIDB5btAfvsoxZl8FFvRhp/OI9JYoUl5mNe/7eiicZ14Xcn2GnMIt/xV1iZg7G/bu7uPcNP9/EOv8j/IyWj/wCAyIS0/hTzsYX2zx6gXq1zHRoXApG/LYBcw+ftfQucvz2+kN8dnKL+KmTldHn8fX2yBL+N8pj2rZj2rPz1tpDeIdtRTnV7iMSjf3GKb70Z/zcnfxJ6oKLZnEzmQ6fvhGL2O5KcyrOp9mGIsm6uJsfEYPvdx0v7n3Tn4tQv+mr8NIFOMcH5NtrfKCjUjIxn53JiF/X4nB86iUT7fLdqlLDTFl5EL2b1kQTf49SryvP5YfPICe/pKAM4+tMd5269IDighHzwvS9J7DvXDIiWIY5h4wd7MXCl3btDwqSR//ZgbpebghlXLdzkJJv6pxLC1/cb83RGBxPTi/ujTeX78f9XRuDLzO7oFsQerLUa+uPncMZ1tHVuJ92Gzu2vw6ewmZ2/lfrtp7hq1XnbkcjP3fsOJmAHj+svmRUOfkFmL+/ZJm+YXtNyM7Dfe3rXTCOPUxvz+mkEtfTOVCYu//qB3/R5PjV1ghNoMwmk63X2OZUBmPSsnDHL2ux9oRxMBuflYPu05YiyyS05h2MLlGO4h5vrTuE1vUC0C7Qp/gl8/nqI2f57JQUhEfOp2JTVKw53JUeRPEtcj/vMTL9eU8U1PnVOjWQe2vpXqSz7Ol5+cgw5TctJw8dvliiRXuebzdcuPf4JZ+rQT+tRq/GgWgd6F1qdtSQaQmfmbj0km/UPMBnd7OpPkq9+RKeW/mszL6MertENNf9sgj1647U+iI8zgfwtUW7riljP/HBeHnVAXYYRs1Cj0yNgB+gljFy7g6sjopDMh/GNzeEI4UDialbj+nBtO/Z1FIOnTmP6OQMONjaaK8l/Y0d+qg5OzCTD0eGrtlZSLUt7FBHM+4nVhxA8nV4hel7K/ZjVWQsdtDa8Pmm8CL5u9yTabQkvNW/JZ7t0hCz7uiMg+wYTpDxMnaa++NS8czKA5hA7SCcx8opbWxO+FkMp+b51a5I5BVjqMJM2xmJmPQsHIlLVqeaEHif2vc983dhFbkqzc7SqThnHzqlxTmNAjC32HXLsJc6fmPpPi3IxxvDMZdxXq2bQUG65KHeeLZTQ3wyuBVOxhgF7kzW+1ZqVJ9QO9tCS89x1v9/mOaDC3bjkNKgbCwqnInvjEnGwiNnkETBd4ZcVVlXsM7uZvipFLZKi7d06roSMk8s248HGOawFmdRXpbhL3V8iO84f3n+DmTk5eHTDYfwr0m7vtR9F7quBnwvrjqIt25rwyDGfH258zgtGXl4Z9NhnGc5VUe8gUJCtRFVxtRi2vZcCuuDHCid5eCAQHg9H3/QsjOSg8tf9p0s1bK142wi7qC2+zgHi3F8Hg2mtC+Uz4v576eV4K0VxnbyFp8hdX61bndsKmp5ueKVHk3xGv/e6dkUSew33t9yBFkU7O/yWznVpJcfj8No9g9f8Pko/gwoS00yB2Dh8cnIJEv1muMfOeAYxTLP5oBdDR4KnY1mCdhExqNnb8PbtA4kZZW0aBSGv/TRv1Q+PmVfZ21OftDF2mqkjPKTyU7iqX8p2C37OtWXqnPTt7ebE6b0a15qDqZQg1R/EyiwdKdMY+0/XYIFE/rC39UBA35Yg4Xs1HvX8cdnDnboVstXD6p9N6d27uPihO61/eBiZ48hv62Hl7sTPucPrIyZsx0Lwk7jj9GdGNaYyeU00T9Ac/ScB3tTaOXj9m9X497ODYvEaXnyGvOWlM4OXy+XftFCZsSnFmoYx8+l4CkKTXN4i3A6p94Nq2J4cE09Ju17xYTecGX5lMstKEAKNY3qZPc+H/DZuyOxZHwfHE5IxzBqZuGThuAN/pjOLE4bzLurCxYfi8XGw6fxUOcG2v36R5caPnB2tEf3Wv6ahthx2hKM7xGMyd0aYeD3q/EiGT0SEqQHxxR2SjNpdZjLOFdQ6K85cBJPdWlkvq4ffLQ+HNFJJqvABeo+jR2+7tZx8PGU6uws2kVxPkOb10S/elX1W8zfU29pCfUu7DAKxReWhaJzMyO3L7Yfw7ETcRjE/I9rUQMhHy3EK7e1RY9afhhEi062oahmWZNtopa3G8CBX1N/d7xLwffbrigsuLsbZoefRv0pc3DyjdHmdDPZDjtPW4TnB7RB/7r+GPjtKmRSAyzNRSak4TOTuVe7rrcVi7qPTmIboeDUHL9WUkCk6e1Kj9SSJf3ubBWELkH++tUi31/tOA5ne1vU5nvTN5sGOp1r+uJ/dnboyWfF1d4OsSlZ+H971wIcVXWG/7w2r02yeQdCHrtJJoQQgoQEykveAUrp1BGxSrG1ImqZFqiOdpjajm0RI0orLW3Fdoq21rbKO7SAiLxRK4yilIcQkFcSggGyEt70++7eu3uz3E0CiCZw/pmwd+8999xzvnP+97/cX635SF65s5fc9epGOQZl9QwMR4O6IPqRYLdJr/QEiQsPlXFoE4b7fj+mh9wPo3rxRwdl4b19jeayFamYMS++Ja+Dd4JhNI15abUM75LuvW4+4P9v/xT5OtCa4/x+GGJmemnTHnmTqQ8zDiYM2fZJyJIkvGfBn3bXnpDD4MOMn/0Dl4LlcRg7U3vlyoDMJPktcLo9I1m75djpRllXVSOzh3WV+/71DnhNZFqZL3JTnByrtSvtEC8JkTYpB7/ld0iU2YMLZcKCd+Wv4MU37iEmnkEu3VMj339lnax4ZJjsxRrfC/kzvjRH68P/H3rw5C//vW+e75aDdViDtucXK6Xuv5o36XdaubW08puhi+Yd20w74xI9EFtIsPwJ3uf9PV2yZtJQiYsMky5Q3uFhodIbispMDLk7wHy9cD48NEh2IZy+a8JoiYSCXHvfAMmesVD3RDx3PQ1BMxlvDzP6GYtnNEfH4ekep/ANROBtn7UfJBehjGtxTxMi/5uEUwNCwP4UF+55i9ki5PEm/n2jLPju7doceOukQYWa4KXwnb5im6ag5739scwf31/yMf/cBLvM3bDDv0uhYCJmfSDstxyql2wIrOlQ6BTINJT6z10pD3bL1O47ByX2wooPZPGDQ7Q0Rh4E/h8CeAz18GpbWvdLJi//NDylltqfPmutMG26gFsLgcjIgdukCEYUZsifx5TI2zDUil1pMrmHU3PQ1/xgmJTNXdUEjzS8ICMzNkqCgoMl3R4pzyJUWzlpuBbWfwxGHef6PrxQgzbiTWpdM1NkWin7DJKlMKpKA6R/zsEIu2LNjY70tT95RjcMeR57gd6j9x6//WHc2tQrNM4i4gKFWQlDhAbdJozToJK0OAmFAdQvPREKP0SioKgXfruvto/uLM2VDTuhME2Un0iDOAL7xCGx2H9bEfH65NFviN0WIsvv6i1ZMxaJuY5lxtodMrF/gfTVDeuJ/TrLAYTgrag1suGkFh3xMQYxqnX7vjfpV8fIx2tNrkoqvPQnhhfLhG4ZUO5n5I6/rJXyvDTpA54JCQ6Rvp3i5UNEWxIiwuWn8OLjI2xyB4ym9xgqNyn1Qip1GH49gMnHMKKPwmDbPGmY9rB/justRc9V6g/mOC/Ly9uq5KlvlUkJeI1/m/rlI7J4JX/zJq6nd831Xvw/GsEHSqn7o6K+fykIkMfsYJDXNKv1i3skvdV3p46SWfCknqjcKjXuszL/7j7yNU2Z86mB6LIW+qJ1TYVOCgFzUqkdodeoy4rP0R/flGVQDpj4iOF1GidNn7/7Zk/TN+vDLs8u1S9cllzk4a4FEyqsyQivfwjB+u+HhkrP1DitTw47PznG+2AqGLa9ACUco3ssnGd2gsfD8Db0O9gJgdYJc6VCJyVAqF1A6sHIv16AMXUBNQcxOE8KQTsXDAYrmlFebHW6yblMKASDRkHQVpg8RON8az6XoPBoZE6KPFzikgduc0rhc8ukASFRUgGUGGlb/eeSCYz0qUkqIjdWglHfAlrO9RLwo7FICoOiz02Ok4ZGnzDejaLMjsl2TaGzTVKUTWzA2Yo6A9eW1nzlvhoZO6/Ge/toRBhmDC30fr+ag3GvbhZHeIg8jYKwAyfcsgOKZwUKPrv75YCjw328EISxW2RovI+lURcLZU6FTuI+iYRR8KnJoD3VcFY6On28k479ceAzt7cP8wHfMtYSJksw5ikL3vHe9uPBXWVM7pXRGm+DZg4GIkJTnp2s8XwSjXxEOFiDkVuEyE6QT25wrcMRzSB5eKlpRMf8iJOYe7TNww88zzcxnm2yB4KEbYpTPPtQa4PIyUmkAqxoCObGv+boJ3A61n0SuGixuXtv5LW2Fzu4kbO9RfuOggeVowvV64fAx1gsnpsOj7ECYdf18NLHlThlzhZPPuwylBlzndYUBK/DpuWQjQpgFiexUKZLvB1GtUcgdwazr66q8/az+AsoSnFBqDMkSOvf2YJytR67yKPIUbqhrDZjzoZCZ1vO1iSTtNujwoIlCQV17+teGvN+70FpNEeDMe/1yNexLTHceKRe0tIcXgOIoVyHww5vrV7rhvnV9Si+u1bKBSYkV0KMpMVEXms38ss3t6MI8ZQ2ZqZmzgOQaKQUSBG6cL47J1U2IM1yGmPWcuXImTbiOBA5oKziMCbOle0/Q2U7Cw3TYn3jHIEQNvvkLybYhpGCRotCy0DP8D9vDwuTnNR4zVjKBibX82rNSQMLZED3bIlLi5Vo9BWGNE2MYagCH4NDrE0Q/5F5vjMiQl7ZgWJPshiNaXfjebkNqQqDemAPrUONh/FLiuUo+PM9zWjV+k8aETSmSDn4NKJVre/B1/KhRf/15s1pqLIup2Mi0i0kYsJJka4ClLwUu5xANIH1CaS1CI3HwyjwkKe/IhQY/hG5eWLCtNn6fcf069f2kYookhNr2tZIhd/b2orcgPEw97TpYU9Y6vq7NxhFJDMmQvZDoDgrFosLjL4djLTykeHaI4IhdHJmL5d9077u90gaBR4mmzakm3SfVSlFyCNv318tL37HE8Y2rs9DsVXRCyukU8USYYjYDm/mqjjd78n8ugyhcoNG5ncwDq/qc9kH+6UOeecEKF6DdvxolKUMohf1H+Tgy4DFnA27pfakW2KAW3PUCdeLnSnimrlYOsLwOFhTL9uQmycROfa5EevZ4/lKmYmf1NUgzB3XQp/azQH+eWviYO3Ka2N7BWjRutPzUQ9ROmuJFGSlyAEUUhWmJ2lj1WSzZ8m1yEsGUhBZmBvDsHUYuw2GTyCit7Z+crmGXwVCyofq3DIe+dcyeLpvQJGTnMi/56U6xDlzkaTiuAZKItQr0AP1HPh8H4Sst04ZqTX4G0Lb10P3mLy91VCy52Fs9IGBTW+7FjzSCThs+eEILKzPWG7ueUaE48ny7tLz+eVSlJUoOw/Uym/G9WuiaH8xqEB6zlkpGc8soZsroQjx+9e4NPcc/2sDke8e+D0P76zSP/3btPb7VITUy369XBagSLb6eIP0zesgo+G5szYiDCmxjrOWyaoHBl3Znb6HrrwgkgfD+fHh3SX7569LXlay/A8Fti+PZz7dR48h3F4CnnHurUbk65xcAsd2KEj3NbjKoym9kY/nXxsj9T71NrYgbX04x+ApRSCsFaPnlZmj3IuQ4hkWi8EDYT6UdBTKvvH8eXHR8zbRUXjkKWjDMDTpEHJqx5DXToyOkAycp9Ci154OJUXlRS90H8KGERD8DKnRyrYqvjE94oYfVkFp+Fewu6CojkNQRMKLirF5QsX7ERbOdkRp42H18WHMy4Fwsw06LBYGihE+NQbMqnAnFB2J3so+pBrofaYjTJikh9qZN3XpfdaiT/6MjXUK4VBijogwrzdv9Pllf1Zj3avdjRKNVEpuQrQWNuUax8DTM7w7ruFOeJkMMefGR8tRhEWNORnjrcM+IzE8S+K+496xY98Zbem1k5jGMfeZA8V+FEVWOYhmtCVintaNivpk7AESx88akCzgdBiFck59XU9hzVnY6h8hqAaOnKtRu3AE32vAOwngCxrYDFFzP6SZeQd7NQJ1L4koPrwIpenf51eFD38lU4VUTCT3CfYA5QH3fDV+euaG3MgCHxwCP2RjLSkHGLUifv7j3wPZk4m24eA73l8FHBvgsacikpMGXHjuU/wygnKJbfgLm10wJLg/maYhH6cAm5uJlFK/mVZTzUUhoBBQCCgEbmkEAse9bmlY1OQVAgoBhYBCQCHQ/hBQSr39rZkasUJAIaAQUAgoBCwRUErdEhZ1UiGgEFAIKAQUAu0PAaXU29+aqRErBBQCCgGFgELAEgGl1C1hUScVAgoBhYBCQCHQ/hBQSr39rZkasUJAIaAQUAgoBCwRUErdEhZ1UiGgEFAIKAQUAu0PAaXU29+aqRErBBQCCgGFgELAEgGl1C1hUScVAgoBhYBCQCHQ/hBQSr39rZkasUJAIaAQUAgoBCwR+D+R1ddY+FdCgQAAAABJRU5ErkJggg==)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDQdYopuQqo3"
   },
   "source": [
    "We then run one experiment on each fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZ6bWXW2Q3vX"
   },
   "source": [
    "Cross-validation gives a more accurate measure of model quality, \n",
    "which is especially important if you are making a lot of modeling decisions. However, it can take longer to run, because it estimates multiple models (one for each fold)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-ckUwjiQ9gN"
   },
   "source": [
    "**When should we use cross validation?**\n",
    " - For small datasets, where extra computational burden isn't a big deal, you should run cross-validation.\n",
    "\n",
    " - For larger datasets, a single validation set is sufficient. Your code will run faster, and you may have enough data that there's little need to re-use some of it for holdout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgeRBSEsSI3y"
   },
   "source": [
    "### **Hands on** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qTzVgK1VBHr5"
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "train_data = pd.read_csv(url_train)\n",
    "test_data = pd.read_csv(url_test)\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = train_data.SalePrice              \n",
    "train_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Select numeric columns only\n",
    "numeric_cols = [cname for cname in train_data.columns if train_data[cname].dtype in ['int64', 'float64']]\n",
    "X = train_data[numeric_cols].copy()\n",
    "X_test = test_data[numeric_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8ZKIZ0nS-3W"
   },
   "source": [
    "Here for simplicity, we have dropped the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9DpurhuSm64",
    "outputId": "67745e57-a14f-43a0-f813-a716467f56b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotFrontage  LotArea  ...  PoolArea  MiscVal  MoSold  YrSold\n",
       "0   1          60         65.0     8450  ...         0        0       2    2008\n",
       "1   2          20         80.0     9600  ...         0        0       5    2007\n",
       "2   3          60         68.0    11250  ...         0        0       9    2008\n",
       "3   4          70         60.0     9550  ...         0        0       2    2006\n",
       "4   5          60         84.0    14260  ...         0        0      12    2008\n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25NOorVcTWdZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', SimpleImputer()),\n",
    "    ('model', RandomForestRegressor(n_estimators=50, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9V9bNca0TgDG"
   },
   "source": [
    "The code below uses the **cross_val_score()** function to obtain the mean absolute error (MAE), averaged across five different folds. Recall we set the number of folds with the cv parameter.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8eLj4xITcqd",
    "outputId": "9a6efd4e-af89-4931-a929-a79b017eecc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE score: 18311.538589041094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"Average MAE score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onN_80zyUJbb"
   },
   "source": [
    "Using cross-validation yields a much better measure of model quality, with the added benefit of cleaning up our code. We no longer need to keep track of separate training and validation sets. So, especially for small datasets, it's a good improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygDS8CC9LPv3"
   },
   "source": [
    "# **5. XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MkGscjVMdg3"
   },
   "source": [
    "### This module will demonstrate how to build and optimize models with **gradient boosting**. This method dominates many Kaggle competitions and achieves state-of-the-art results on a variety of datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HS7GJhCNU10"
   },
   "source": [
    "Gradient boosting is a method that goes through cycles to iteratively add models into an ensemble.\n",
    "\n",
    "It begins by initializing the ensemble with a single model, whose predictions can be pretty naive. (Even if its predictions are wildly inaccurate, subsequent additions to the ensemble will address those errors.)\n",
    "\n",
    "Then, we start the cycle:\n",
    "\n",
    " - First, we use the current ensemble to generate predictions for each observation in the dataset. To make a prediction, we add the predictions from all models in the ensemble.\n",
    " - These predictions are used to calculate a loss function (like mean squared error, for instance).\n",
    " - Then, we use the loss function to fit a new model that will be added to the ensemble. Specifically, we determine model parameters so that adding this new model to the ensemble will reduce the loss. (Side note: The \"gradient\" in \"gradient boosting\" refers to the fact that we'll use gradient descent on the loss function to determine the parameters in this new model.)\n",
    " - Finally, we add the new model to ensemble, and ...\n",
    " - ... repeat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OD7vJ6mUNhkI"
   },
   "source": [
    "![Screen Shot 2020-10-30 at 11 52 43 AM](https://user-images.githubusercontent.com/56054175/97792779-4e361900-1bb9-11eb-9682-29e5c3873ea6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdVVkA7vNql7"
   },
   "source": [
    "For our hands on we will be using **XGBoost**. It stands for **extreme gradient boosting**, which is an implementation of gradient boosting with several additional features focused on performance and speed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tZPuhtoO7lr"
   },
   "source": [
    "### **Hands on** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntGl941JTm-Q"
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "X = pd.read_csv(url_train)\n",
    "X_test_full = pd.read_csv(url_test)\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice              \n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numeric_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()\n",
    "\n",
    "# One-hot encode the data (to shorten the code, we use pandas)\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_valid = pd.get_dummies(X_valid)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "X_train, X_valid = X_train.align(X_valid, join='left', axis=1)\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Rjn-RsoR2GT"
   },
   "source": [
    "###Step 1: **Building the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWBt7665SAlC"
   },
   "source": [
    "XGBoost has a few parameters that can dramatically affect accuracy and training speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IEKaXAQS9jr"
   },
   "source": [
    "Firstly, we will build an XGBoost model using default parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HWcGBeeRZHL",
    "outputId": "e7771a73-c475-456a-9fe7-11f0b91f6b8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:12:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "# Define the model\n",
    "my_model_1 = XGBRegressor(random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "my_model_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsUk2dQpSfiK"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Get predictions\n",
    "predictions_1 = my_model_1.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRRqHy6ASpQl",
    "outputId": "05b6f8c2-058a-4654-b7c9-3c9e86ca3e64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 16997.531464041094\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAE\n",
    "mae_1 = mean_absolute_error(predictions_1, y_valid)\n",
    "print(\"Mean Absolute Error:\" , mae_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jhil4Lg2TFHB"
   },
   "source": [
    "Now its time to improve the model by changing the default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPoosZ4eTRWc"
   },
   "source": [
    "###Step 2: **Improving the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Je9y71igTkky"
   },
   "source": [
    "To improve the model, we are going to change the default parameters. Some of the parameters that can be changed are \n",
    "\n",
    "1. **n_estimators** :\n",
    "-   Specifies how many times to go through the modeling cycle described above. It is equal to the number of models that we include in the ensemble\n",
    "-  Too low a value causes underfitting, which leads to inaccurate predictions on both training data and test data.\n",
    "-  Too high a value causes overfitting, which causes accurate predictions on training data, but inaccurate predictions on test data (which is what we care about).\n",
    "-  Typical values range from 100-1000\n",
    "\n",
    "\n",
    "\n",
    "2. **early_stopping_rounds** :\n",
    "- Offers a way to automatically find the ideal value for n_estimators\n",
    "- Early stopping causes the model to stop iterating when the validation score stops improving, even if we aren't at the hard stop for n_estimators\n",
    "-  It's smart to set a high value for n_estimators and then use early_stopping_rounds to find the optimal time to stop iterating.\n",
    "- When using early_stopping_rounds, you also need to set aside some data for calculating the validation scores - this is done by setting the eval_set parameter.\n",
    "\n",
    "\n",
    "3. **learning_rate** : \n",
    "- Instead of getting predictions by simply adding up the predictions from each component model, we can multiply the predictions from each model by a small number (known as the learning rate) before adding them in.\n",
    "- This means each tree we add to the ensemble helps us less. So, we can set a higher value for n_estimators without overfitting. If we use early stopping, the appropriate number of trees will be determined automatically.\n",
    "- In general, **a small learning rate and large number of estimators will yield more accurate XGBoost models**, though it will also take the model longer to train since it does more iterations through the cycle. As default, XGBoost sets learning_rate=0.1.\n",
    "\n",
    "4. **n_jobs** :\n",
    "- On larger datasets where runtime is a consideration, you can use parallelism to build your models faster. It's common to set the parameter n_jobs equal to the number of cores on your machine. On smaller datasets, this won't help.\n",
    "- The resulting model won't be any better, so micro-optimizing for fitting time is typically nothing but a distraction. But, it's useful in large datasets where you would otherwise spend a long time waiting during the fit command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSO4EG_BSwfL",
    "outputId": "cfa03a03-4cd1-4e31-e95a-74d26ca7e60b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:12:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Mean Absolute Error: 16375.472442208904\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "my_model_2 = XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "\n",
    "# Fit the model\n",
    "my_model_2.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "predictions_2 = my_model_2.predict(X_valid)\n",
    "\n",
    "# Calculate MAE\n",
    "mae_2 = mean_absolute_error(predictions_2, y_valid)\n",
    "print(\"Mean Absolute Error:\" , mae_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6-1dcR_Y5AI"
   },
   "source": [
    "There is a drop in the error due to the addition of n_estimators and learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GA9qbDmwZqDy"
   },
   "source": [
    "Playing the parameters to improve the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FUi8SMArTheQ",
    "outputId": "8802e75c-c0fc-4c0d-f6c6-c7e2a808a540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:12:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Mean Absolute Error: 16045.883842572774\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "my_model_3 = XGBRegressor(n_estimators=1000, learning_rate=0.03)\n",
    "\n",
    "# Fit the model\n",
    "my_model_3.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "predictions_3 = my_model_3.predict(X_valid)\n",
    "\n",
    "# Calculate MAE\n",
    "mae_3 = mean_absolute_error(predictions_3, y_valid)\n",
    "print(\"Mean Absolute Error:\" , mae_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDaBNQFUZxS7"
   },
   "source": [
    "Hence, XGBoost is a the leading software library for working with standard tabular data (the type of data you store in Pandas DataFrames, as opposed to more exotic types of data like images and videos). With careful parameter tuning, you can train highly accurate models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_U81pHst-XZ"
   },
   "source": [
    "## **EXTRA : XGBoost in parallel processing**\n",
    "- In XGBoost, the parallelisation happens during the construction of each trees, at a very low level. Each independent branches of the tree are trained separately. \n",
    "\n",
    "- Hyperparameters tuning requires many branches per tree and many trees per model and several models per hyperparameters value and many hyperparameters values to be tested\n",
    "\n",
    "- The XGBoost library for gradient boosting uses is designed for efficient multi-core parallel processing\n",
    "\n",
    "- This allows it to efficiently use all of the CPU cores in your system when training\n",
    "\n",
    "- The parallelism in gradient boosting can be implemented in the construction of individual trees, rather than in creating trees in parallel like random forest. This is because in boosting, trees are added to the model sequentially\n",
    "\n",
    "- The speed of XGBoost is both in adding parallelism in the construction of individual trees, and in the efficient preparation of the input data to aid in the speed up in the construction of trees\n",
    "\n",
    "- The XGBClassifier and XGBRegressor wrapper classes for XGBoost for use in scikit-learn provide the nthread parameter to specify the number of threads that XGBoost can use during training\n",
    "\n",
    "- By default this parameter is set to -1 to make use of all of the cores in your system \n",
    "\n",
    "\n",
    "```\n",
    "     model = XGBClassifier(nthread=-1)\n",
    "```\n",
    "\n",
    " - Moreover, parallelisation has one main drawback: the overhead. Before any parallel computation, data has to be sent to each cores. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdjGGTe-HYme"
   },
   "source": [
    "# **6. Data Leakage**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeTzAUSlHlgc"
   },
   "source": [
    "### **Data leakage** (or leakage) happens when your training data contains information about the target, but similar data will not be available when the model is used for prediction. This leads to high performance on the training set (and possibly even the validation data), but the model will perform poorly in production.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPGFcriKJH7B"
   },
   "source": [
    "There are two main types of leakage: \n",
    "1. Target leakage \n",
    "2. Train-test contamination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8g9RoYnAONpj"
   },
   "source": [
    "### Target Leakage\n",
    "Target leakage occurs when your predictors include data that will not be available at the time you make predictions. It is important to think about target leakage in terms of the timing or chronological order that data becomes available, not merely whether a feature helps make good predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_icj7bqOXAL"
   },
   "source": [
    "### Train-Test contamination\n",
    "A different type of leak occurs when you aren't careful to distinguish training data from validation data.\n",
    "\n",
    "Recall that validation is meant to be a measure of how the model does on data that it hasn't considered before. You can corrupt this process in subtle ways if the validation data affects the preprocessing behavior. This is sometimes called train-test contamination.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQBtd2y2OzcB"
   },
   "source": [
    "For example, imagine you run preprocessing (like fitting an imputer for missing values) before calling train_test_split(). The end result? Your model may get good validation scores, giving you great confidence in it, but perform poorly when you deploy it to make decisions.\n",
    "\n",
    "\n",
    "After all, you incorporated data from the validation or test data into how you make predictions, so the may do well on that particular data even if it can't generalize to new data. This problem becomes even more subtle (and more dangerous) when you do more complex feature engineering.\n",
    "\n",
    "\n",
    "\n",
    "If your validation is based on a simple train-test split, exclude the validation data from any type of fitting, including the fitting of preprocessing steps. This is easier if you use scikit-learn pipelines. When using cross-validation, it's even more critical that you do your preprocessing inside the pipeline!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TPZS-jy-O_X"
   },
   "source": [
    "## **Conclusion**\n",
    "Hence, this notebook demonstrated how to improve you machine learning models - how to tackle categorical and numerical data types, how to use advanced techniques for model validation, how to avoid the problems of data leakage, as well as building pipeline to improve the code\n",
    "\n",
    "Also usage of XGBoost was demonstrated along with hands on code. This notebook also mentioned the how XGBoost uses parallel processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z19htKJM8Xmr"
   },
   "source": [
    "## **Citations** \n",
    "\n",
    "https://www.kaggle.com/learn/intermediate-machine-learning\n",
    "\n",
    "https://machinelearningmastery.com/best-tune-multithreading-support-xgboost-python/\n",
    "\n",
    "https://medium.com/blablacar/thinking-before-building-xgboost-parallelization-f1a3f37b6e68\n",
    "\n",
    "https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/\n",
    "\n",
    "https://www.youtube.com/watch?v=OQKQHNCVf5k&ab_channel=SundogEducationwithFrankKane\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7rJ7i_oq046"
   },
   "source": [
    "## **Licensing** \n",
    "\n",
    "\n",
    "Copyright 2020 Rohan Kapadnis\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "RohanKapadnis_MiniProject-1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
